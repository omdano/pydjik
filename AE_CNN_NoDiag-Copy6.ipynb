{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca7e12d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ca7e12d6",
    "outputId": "3bbf9b52-99e4-4287-d33f-f3c380463889"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef force_cudnn_initialization():\\n    s = 32\\n    dev = torch.device('cuda')\\n    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "import scipy.ndimage\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\"\"\"\n",
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "A1X1Rv_u1_tw",
   "metadata": {
    "id": "A1X1Rv_u1_tw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1 cuda\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
    "#!pip install torchmetrics\n",
    "#!pip install numpy==1.21 --user\n",
    "#!pip install matplotlib --user\n",
    "print(torch.__version__, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6732272c",
   "metadata": {
    "id": "6732272c"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.utils import (\n",
    "    add_self_loops,\n",
    "    remove_self_loops,\n",
    "    sort_edge_index,\n",
    "    add_remaining_self_loops,\n",
    "    to_undirected,\n",
    "    degree,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IwV69rXdxDji",
   "metadata": {
    "id": "IwV69rXdxDji"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef384d5b",
   "metadata": {
    "id": "ef384d5b"
   },
   "outputs": [],
   "source": [
    "graph_size = 128\n",
    "BATCH_SIZE = 4\n",
    "NUM_PATHS = 4\n",
    "\n",
    "gs = torch.Tensor(graph_size).to(device)\n",
    "G = nx.grid_graph([graph_size, graph_size])\n",
    "\"\"\"\n",
    "G.add_edges_from([\n",
    "    ((x, y), (x+1, y+1))\n",
    "    for x in range(3)\n",
    "    for y in range(3)\n",
    "] + [\n",
    "    ((x+1, y), (x, y+1))\n",
    "    for x in range(3)\n",
    "    for y in range(3)\n",
    "], weight=1.4)\n",
    "\"\"\"\n",
    "edges = list(G.edges)\n",
    "nedges = []\n",
    "for i in range(len(edges)):\n",
    "    nedges.append([edges[i][0][0] * graph_size + edges[i][0][1]\n",
    "                   , edges[i][1][0] * graph_size + edges[i][1][1]])\n",
    "edge_maps = np.asarray(nedges).astype(np.int32).T\n",
    "edge_maps = torch.LongTensor(edge_maps)\n",
    "edge_maps = to_undirected(edge_maps).numpy()\n",
    "self_connects = np.arange(graph_size*graph_size, dtype=np.int32)\n",
    "self_connects = np.tile(np.expand_dims(self_connects, axis=0), [2,1])\n",
    "edge_maps = np.concatenate([edge_maps, self_connects], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5CcKbYjUxjh",
   "metadata": {
    "id": "a5CcKbYjUxjh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     1, ..., 16381, 16382, 16383],\n",
       "       [    1,   128,     0, ..., 16381, 16382, 16383]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85423347",
   "metadata": {
    "id": "85423347"
   },
   "outputs": [],
   "source": [
    "#edges_maps = np.concatenate([edge_maps, edge_maps[::-1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925ab79",
   "metadata": {
    "id": "a925ab79"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3780f9a2",
   "metadata": {
    "id": "3780f9a2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "701383a1",
   "metadata": {
    "id": "701383a1"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.utils import to_networkx, coalesce\n",
    "def dist(a, b):\n",
    "    (x1, y1) = a//graph_size, a%graph_size\n",
    "    (x2, y2) = b//graph_size, b%graph_size\n",
    "    return ((x1 - x2) ** 2 + (y1 - y2) ** 2) ** 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b5729f",
   "metadata": {
    "id": "85b5729f"
   },
   "outputs": [],
   "source": [
    "depth = np.asarray([2])\n",
    "rem_depth = np.maximum((np.log2(graph_size // (2**depth))).astype(np.int32) - 2, 0)\n",
    "reduction_rate = (2**depth)\n",
    "enc_size = graph_size // reduction_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88f38ea9",
   "metadata": {
    "id": "88f38ea9"
   },
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "import cv2\n",
    "from torch_geometric.transforms.add_positional_encoding import AddLaplacianEigenvectorPE\n",
    "from numpy.random import RandomState\n",
    "class RandomImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, graph_size=64, mfill_rate=0.5, sfill_rate=0.135, steps=128):\n",
    "        super().__init__()\n",
    "        self.graph_size = graph_size\n",
    "        self.mfill_rate = mfill_rate\n",
    "        self.sfill_rate = sfill_rate\n",
    "        self.steps = steps\n",
    "        #self.transform = AddLaplacianEigenvectorPE(4, None, is_undirected=True)\n",
    "\n",
    "    def len(self):\n",
    "        return self.steps#len(self.img_labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        graph_size = self.graph_size\n",
    "        mfill_rate = self.mfill_rate\n",
    "        sfill_rate = self.sfill_rate\n",
    "        i_ = 0\n",
    "        t0 = time.time()\n",
    "        while True:\n",
    "            tt = time.time()\n",
    "            fill_rate = np.random.random()*0.75 + 0.1\n",
    "            r = (np.random.choice(2, graph_size*graph_size,\n",
    "            p=[1-fill_rate, fill_rate])).reshape(graph_size*graph_size, 1)\n",
    "            map = r.reshape(graph_size, graph_size, 1)\n",
    "            label, num = scipy.ndimage.label(1 - map)\n",
    "            #print(\"map gen\", time.time() - tt)\n",
    "            probs = np.zeros((num+1,))\n",
    "            #for i in range(1,num):\n",
    "            #    probs[i] = (label == i).sum()\n",
    "            u, c = np.unique(label, return_counts=True)\n",
    "            #print(\"unique counts:\", u, c)\n",
    "            umask = u>0\n",
    "            c = c[umask]\n",
    "            u = u[umask]\n",
    "            probs[u.astype(np.int32)] = c\n",
    "            probs = probs * (probs > 200)\n",
    "            #print(\"map gen 1 \", time.time() - tt)\n",
    "            if probs.sum() > 0:\n",
    "                break\n",
    "            t1 = time.time()\n",
    "            #print(f\"loop {i_} {t1 - t0}: \", probs, fill_rate, r.sum())\n",
    "            i_ += 1\n",
    "        #print(\"loop out: \", time.time() - t0)\n",
    "        \n",
    "        \n",
    "        probs = probs/probs.sum()\n",
    "        start = np.zeros((NUM_PATHS, 2))\n",
    "        end = np.zeros((NUM_PATHS, 2))        \n",
    "        for i in range(NUM_PATHS):\n",
    "            chosen = np.random.choice(range(1,probs.shape[0]+1), p=probs) - 1\n",
    "            clust = np.argwhere(label == chosen)[:,:-1]\n",
    "            link = np.arange(clust.shape[0])\n",
    "            np.random.shuffle(link)\n",
    "            cur_pos = clust[link[0]]\n",
    "            rem_pos = clust[link[1:]]\n",
    "            oabs_dist = np.abs(rem_pos[:,0] - cur_pos[0]) + np.abs(rem_pos[:,1] - cur_pos[1])\n",
    "            abs_dist = (oabs_dist)\n",
    "            abs_dist = abs_dist / abs_dist.sum()\n",
    "            end_pos = np.random.choice(np.arange(rem_pos.shape[0]), p=abs_dist)\n",
    "            #print(oabs_dist[end_pos], oabs_dist.max())\n",
    "            end_pos = clust[link[1 + end_pos]]\n",
    "            start[i] = cur_pos\n",
    "            end[i] = end_pos\n",
    "        start = torch.LongTensor(start)\n",
    "        end = torch.LongTensor(end)\n",
    "        map = 1 - map\n",
    "        \n",
    "        movinglabels = np.zeros((map.shape[0], map.shape[1], 1), dtype=np.int64)\n",
    "        for i in range(enc_size[0]):\n",
    "            for j in range(enc_size[0]):\n",
    "                #print(i, reduction_rate[0], i*reduction_rate[0])\n",
    "                map_snip = map[i*reduction_rate[0]:(i+1)*reduction_rate[0], \n",
    "                               j*reduction_rate[0]:(j+1)*reduction_rate[0]]\n",
    "                labelc, num = scipy.ndimage.measurements.label(map_snip)\n",
    "                movinglabels[i*reduction_rate[0]:(i+1)*reduction_rate[0], \n",
    "                               j*reduction_rate[0]:(j+1)*reduction_rate[0]][labelc>0] = labelc[labelc>0] + movinglabels.max()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        map = torch.Tensor(map)\n",
    "        \n",
    "        label2 = torch.LongTensor(label)\n",
    "        label = torch.LongTensor(movinglabels)\n",
    "        \n",
    "        #print(\"TIME TO YIELD: \", time.time() - t0)\n",
    "        \n",
    "        \"\"\"\n",
    "        idx = np.where(r)[0]\n",
    "        gen_grid = r\n",
    "        #print(idx.shape, r.shape, np.isin(edge_maps, idx).shape)\n",
    "        edges = edge_maps[:,~np.isin(edge_maps, idx).any(axis=0)]\n",
    "        r = edges\n",
    "        #print(np.unique(edges[0,:]))\n",
    "        z = np.zeros((self.graph_size*self.graph_size, 1))\n",
    "        onesTens = torch.Tensor(z)\n",
    "        r = torch.LongTensor(r.astype(np.int32))\n",
    "        \n",
    "        dat = Data(x=onesTens, edge_index=r)\n",
    "        dat.num_features = 1\n",
    "        dat.num_nodes = dat.x.shape[0]\n",
    "        #print(dat, , dat.num_nodes)\n",
    "        net = to_networkx(dat)\n",
    "        cur_node = cur_pos[1] + cur_pos[0] * graph_size\n",
    "        end_node = end_pos[1] + end_pos[0] * graph_size\n",
    "        path = nx.shortest_path(net, cur_node, end_node, weight=\"cost\")\n",
    "        y = np.zeros((self.graph_size*self.graph_size, 1))\n",
    "        path = [int(p) for p in path]\n",
    "        y[path] = 1\n",
    "        z = 1-gen_grid\n",
    "        dat.x = torch.Tensor(z)\n",
    "        dat.start = torch.LongTensor([cur_node.astype(np.int64)])\n",
    "        dat.end = torch.LongTensor([end_node.astype(np.int64)])\n",
    "        #print(end_node.astype(np.int64))\n",
    "        #print(dat.end)\n",
    "        dat.y = torch.Tensor(y)\n",
    "        #dat = self.transform(dat)\n",
    "        #pos_encs = dat.x[:,1:]\n",
    "        direction = end_pos - cur_pos\n",
    "        direction = direction / np.sqrt(np.square(direction).sum())\n",
    "        pos = torch.Tensor(direction)\n",
    "        #print(pos.shape)\n",
    "        pos = pos.unsqueeze(0)\n",
    "        \n",
    "        dat.startend = pos#.unsqueeze(0)\n",
    "        \"\"\"\n",
    "        return map, start, end, label, label2 #image_edges\n",
    "\n",
    "\n",
    "class CustomImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, graph_size=512, batch_size=2):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.images = [os.path.join(path, p) for p in os.listdir(path)]\n",
    "        #self.steps = steps\n",
    "        self.gs = graph_size\n",
    "        self.length = len(self.images)\n",
    "        self.bs = batch_size\n",
    "        self.i = 0\n",
    "        self.idx = np.arange(len(self.images))\n",
    "        print(len(self.idx))\n",
    "        #self.prng = RandomState(1234567890)\n",
    "\n",
    "        #self.transform = AddLaplacianEigenvectorPE(4, None, is_undirected=True)\n",
    "\n",
    "    def len(self):\n",
    "        return self.length#len(self.img_labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i_ = 0\n",
    "        t0 = time.time()\n",
    "        #prng = self.prng\n",
    "        while True:\n",
    "            tt = time.time()\n",
    "            image_idx = self.idx[self.i]\n",
    "            self.i += 1\n",
    "            if self.i >= self.length:\n",
    "                self.i = 0 \n",
    "                #np.random.shuffle(self.idx)\n",
    "            #image_idx = np.random.randint(len(self.images))\n",
    "            map = cv2.imread(self.images[image_idx],0)\n",
    "            map = 1*(cv2.resize(map, (self.gs, self.gs)) > 127)\n",
    "            map = map.reshape(graph_size, graph_size, 1)\n",
    "            #print(map.shape)\n",
    "            label, num = scipy.ndimage.label(map)\n",
    "            #print(\"map gen\", time.time() - tt)\n",
    "            probs = np.zeros((num+1,))\n",
    "            #for i in range(1,num):\n",
    "            #    probs[i] = (label == i).sum()\n",
    "            u, c = np.unique(label, return_counts=True)\n",
    "            #print(\"unique counts:\", u, c)\n",
    "            umask = u>0\n",
    "            c = c[umask]\n",
    "            u = u[umask]\n",
    "            probs[u.astype(np.int32)] = c\n",
    "            probs = probs * (probs > 100)\n",
    "            #print(\"map gen 1 \", time.time() - tt)\n",
    "            if probs.sum() > 0:\n",
    "                \n",
    "                #print(image_idx, self.images[image_idx], num)\n",
    "                break\n",
    "            t1 = time.time()\n",
    "            #print(f\"loop {i_} {t1 - t0}: \", probs, fill_rate, r.sum())\n",
    "            i_ += 1\n",
    "        #print(\"loop out: \", time.time() - t0)\n",
    "        \n",
    "        \n",
    "        probs = probs/probs.sum()\n",
    "        start = np.zeros((NUM_PATHS, 2))\n",
    "        end = np.zeros((NUM_PATHS, 2))        \n",
    "        for i in range(NUM_PATHS):\n",
    "            chosen = np.random.choice(range(1,probs.shape[0]+1), p=probs) - 1\n",
    "            clust = np.argwhere(label == chosen)[:,:-1]\n",
    "            link = np.arange(clust.shape[0])\n",
    "            np.random.shuffle(link)\n",
    "            cur_pos = clust[link[0]]\n",
    "            end_pos = clust[link[1]]\n",
    "            start[i] = cur_pos\n",
    "            end[i] = end_pos\n",
    "        start = torch.LongTensor(start)\n",
    "        end = torch.LongTensor(end)\n",
    "        \n",
    "        movinglabels = np.zeros((map.shape[0], map.shape[1], 1), dtype=np.int64)\n",
    "        for i in range(enc_size[0]):\n",
    "            for j in range(enc_size[0]):\n",
    "                #print(i, reduction_rate[0], i*reduction_rate[0])\n",
    "                map_snip = map[i*reduction_rate[0]:(i+1)*reduction_rate[0], \n",
    "                               j*reduction_rate[0]:(j+1)*reduction_rate[0]]\n",
    "                labelc, num = scipy.ndimage.measurements.label(map_snip)\n",
    "                movinglabels[i*reduction_rate[0]:(i+1)*reduction_rate[0], \n",
    "                               j*reduction_rate[0]:(j+1)*reduction_rate[0]][labelc>0] = labelc[labelc>0] + movinglabels.max()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        map = torch.Tensor(map)\n",
    "        \n",
    "        label2 = torch.LongTensor(label)\n",
    "        label = torch.LongTensor(movinglabels)\n",
    "        \n",
    "        #print(\"TIME TO YIELD: \", time.time() - t0)\n",
    "        \n",
    "        \"\"\"\n",
    "        idx = np.where(r)[0]\n",
    "        gen_grid = r\n",
    "        #print(idx.shape, r.shape, np.isin(edge_maps, idx).shape)\n",
    "        edges = edge_maps[:,~np.isin(edge_maps, idx).any(axis=0)]\n",
    "        r = edges\n",
    "        #print(np.unique(edges[0,:]))\n",
    "        z = np.zeros((self.graph_size*self.graph_size, 1))\n",
    "        onesTens = torch.Tensor(z)\n",
    "        r = torch.LongTensor(r.astype(np.int32))\n",
    "        \n",
    "        dat = Data(x=onesTens, edge_index=r)\n",
    "        dat.num_features = 1\n",
    "        dat.num_nodes = dat.x.shape[0]\n",
    "        #print(dat, , dat.num_nodes)\n",
    "        net = to_networkx(dat)\n",
    "        cur_node = cur_pos[1] + cur_pos[0] * graph_size\n",
    "        end_node = end_pos[1] + end_pos[0] * graph_size\n",
    "        path = nx.shortest_path(net, cur_node, end_node, weight=\"cost\")\n",
    "        y = np.zeros((self.graph_size*self.graph_size, 1))\n",
    "        path = [int(p) for p in path]\n",
    "        y[path] = 1\n",
    "        z = 1-gen_grid\n",
    "        dat.x = torch.Tensor(z)\n",
    "        dat.start = torch.LongTensor([cur_node.astype(np.int64)])\n",
    "        dat.end = torch.LongTensor([end_node.astype(np.int64)])\n",
    "        #print(end_node.astype(np.int64))\n",
    "        #print(dat.end)\n",
    "        dat.y = torch.Tensor(y)\n",
    "        #dat = self.transform(dat)\n",
    "        #pos_encs = dat.x[:,1:]\n",
    "        direction = end_pos - cur_pos\n",
    "        direction = direction / np.sqrt(np.square(direction).sum())\n",
    "        pos = torch.Tensor(direction)\n",
    "        #print(pos.shape)\n",
    "        pos = pos.unsqueeze(0)\n",
    "        \n",
    "        dat.startend = pos#.unsqueeze(0)\n",
    "        \"\"\"\n",
    "        return map, start, end, label, label2 #image_edges\n",
    "    \n",
    "\n",
    "TOTAL_IMAGES = 1024 // NUM_PATHS\n",
    "#STEPS = \n",
    "train_data = RandomImageDataset(graph_size, steps=TOTAL_IMAGES)\n",
    "val_data = RandomImageDataset(graph_size)\n",
    "#train_data = CustomImageDataset(\"bg512-png\", graph_size, batch_size = BATCH_SIZE)\n",
    "#val_data = CustomImageDataset(\"bg512-png\", graph_size)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce38b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a50e6e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_rate = np.random.random()*0.75 + 0.1\n",
    "r = (np.random.choice(2, graph_size*graph_size,\n",
    "p=[1-fill_rate, fill_rate])).reshape(graph_size*graph_size, 1)\n",
    "map = r.reshape(graph_size, graph_size, 1)\n",
    "label, num = scipy.ndimage.label(1 - map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "144f662d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 2052 2053 2054] [12861     1     3 ...     1     1     1]\n"
     ]
    }
   ],
   "source": [
    "u, c = np.unique(label, return_counts=True)\n",
    "print(u, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abbbfa51",
   "metadata": {
    "id": "abbbfa51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngraph_size = 128#self.graph_size\\nmfill_rate = 0.4#self.mfill_rate\\nsfill_rate = 0.04#self.sfill_rate\\n\\nfill_rate = min([max([np.random.normal(mfill_rate, sfill_rate), 0.05]), 0.95])\\nwhile True:\\n    r = (np.random.choice(2, graph_size*graph_size,\\n    p=[1-fill_rate, fill_rate])).reshape(graph_size*graph_size, 1)\\n    map = r.reshape(graph_size, graph_size, 1)\\n    label, num = scipy.ndimage.measurements.label(1 - map)\\n    probs = np.zeros((num,))\\n    for i in range(1,num):\\n        probs[i] = (label == i).sum()\\n    probs = probs * (probs > 1)\\n    if probs.sum() > 0:\\n        break\\n\\nimg = batch[0][1].numpy()\\nlabel, num = scipy.ndimage.measurements.label(img)\\nimage_snips = np.zeros((enc_size[0], enc_size[0], reduction_rate[0], reduction_rate[0]))\\nimage_edges = []\\ndat = []\\nfor i in range(image_snips.shape[0]):\\n    for j in range(image_snips.shape[0]):\\n        image_snips[i,j] = label[image_snips.shape[2]*i:image_snips.shape[2]*(i+1),\\n                                 image_snips.shape[2]*j:image_snips.shape[2]*(j+1), 0]\\n        \\nnc = 0        \\nfor i in range(image_snips.shape[0]):\\n    for j in range(image_snips.shape[0]): \\n        loc_data = {}\\n        for uc, un_cluster in enumerate(np.unique(image_snips[i,j].flatten()).astype(np.int32)):\\n            dat = [i,j]\\n            if un_cluster == 0:\\n                continue\\n            loc_data[un_cluster] = []\\n            if i > 0:\\n                cond = (image_snips[i,j, 0, :] == un_cluster) &                         (image_snips[i-1, j, -1, :] == un_cluster)\\n                if cond.any():\\n                    loc_data[un_cluster].append([i*image_snips.shape[0] + j, (i-1)*image_snips.shape[0] + j])\\n            \\n            if j > 0:\\n                cond = (image_snips[i,j, :, 0] == un_cluster) &                         (image_snips[i, j-1, :, -1] == un_cluster)\\n                if cond.any():\\n                    loc_data[un_cluster].append([i*image_snips.shape[0] + j, i*image_snips.shape[0] + (j - 1)])\\n                    \\n            if i < (image_snips.shape[0] - 1):\\n                cond = (image_snips[i,j, -1, :] == un_cluster) &                         (image_snips[i+1, j, 0, :] == un_cluster)\\n                if cond.any():\\n                    loc_data[un_cluster].append([i*image_snips.shape[0] + j, (i+1)*image_snips.shape[0] + j])\\n            \\n            if j < (image_snips.shape[0] - 1):\\n                cond = (image_snips[i,j, :, -1] == un_cluster) &                         (image_snips[i, j+1, :, 0] == un_cluster)\\n                if cond.any():\\n                    loc_data[un_cluster].append([i*image_snips.shape[0] + j, i*image_snips.shape[0] + (j + 1)])\\n        image_edges.append(loc_data)\\n\\nnew_ie = []\\nmappers = []\\nnc = 0\\nfor i in range(len(image_edges)):\\n    mappers.append({k:v+nc for v, k in enumerate(image_edges[i])})\\n    nc += len(image_edges[i])\\n\\nassigner = {}\\nfor i, map_ in enumerate(mappers):\\n    for key in map_:\\n        assigner[(i, key)] = map_[key]\\n    \\nfor i in range(len(image_edges)):\\n    for j in image_edges[i]:\\n        cont = image_edges[i][j]\\n        new_ie.append([mappers[i][j], mappers[i][j]])\\n        for item in cont:\\n            new_ie.append([mappers[item[0]][j], mappers[item[1]][j]])\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "graph_size = 128#self.graph_size\n",
    "mfill_rate = 0.4#self.mfill_rate\n",
    "sfill_rate = 0.04#self.sfill_rate\n",
    "\n",
    "fill_rate = min([max([np.random.normal(mfill_rate, sfill_rate), 0.05]), 0.95])\n",
    "while True:\n",
    "    r = (np.random.choice(2, graph_size*graph_size,\n",
    "    p=[1-fill_rate, fill_rate])).reshape(graph_size*graph_size, 1)\n",
    "    map = r.reshape(graph_size, graph_size, 1)\n",
    "    label, num = scipy.ndimage.measurements.label(1 - map)\n",
    "    probs = np.zeros((num,))\n",
    "    for i in range(1,num):\n",
    "        probs[i] = (label == i).sum()\n",
    "    probs = probs * (probs > 1)\n",
    "    if probs.sum() > 0:\n",
    "        break\n",
    "\n",
    "img = batch[0][1].numpy()\n",
    "label, num = scipy.ndimage.measurements.label(img)\n",
    "image_snips = np.zeros((enc_size[0], enc_size[0], reduction_rate[0], reduction_rate[0]))\n",
    "image_edges = []\n",
    "dat = []\n",
    "for i in range(image_snips.shape[0]):\n",
    "    for j in range(image_snips.shape[0]):\n",
    "        image_snips[i,j] = label[image_snips.shape[2]*i:image_snips.shape[2]*(i+1),\n",
    "                                 image_snips.shape[2]*j:image_snips.shape[2]*(j+1), 0]\n",
    "        \n",
    "nc = 0        \n",
    "for i in range(image_snips.shape[0]):\n",
    "    for j in range(image_snips.shape[0]): \n",
    "        loc_data = {}\n",
    "        for uc, un_cluster in enumerate(np.unique(image_snips[i,j].flatten()).astype(np.int32)):\n",
    "            dat = [i,j]\n",
    "            if un_cluster == 0:\n",
    "                continue\n",
    "            loc_data[un_cluster] = []\n",
    "            if i > 0:\n",
    "                cond = (image_snips[i,j, 0, :] == un_cluster) & \\\n",
    "                        (image_snips[i-1, j, -1, :] == un_cluster)\n",
    "                if cond.any():\n",
    "                    loc_data[un_cluster].append([i*image_snips.shape[0] + j, (i-1)*image_snips.shape[0] + j])\n",
    "            \n",
    "            if j > 0:\n",
    "                cond = (image_snips[i,j, :, 0] == un_cluster) & \\\n",
    "                        (image_snips[i, j-1, :, -1] == un_cluster)\n",
    "                if cond.any():\n",
    "                    loc_data[un_cluster].append([i*image_snips.shape[0] + j, i*image_snips.shape[0] + (j - 1)])\n",
    "                    \n",
    "            if i < (image_snips.shape[0] - 1):\n",
    "                cond = (image_snips[i,j, -1, :] == un_cluster) & \\\n",
    "                        (image_snips[i+1, j, 0, :] == un_cluster)\n",
    "                if cond.any():\n",
    "                    loc_data[un_cluster].append([i*image_snips.shape[0] + j, (i+1)*image_snips.shape[0] + j])\n",
    "            \n",
    "            if j < (image_snips.shape[0] - 1):\n",
    "                cond = (image_snips[i,j, :, -1] == un_cluster) & \\\n",
    "                        (image_snips[i, j+1, :, 0] == un_cluster)\n",
    "                if cond.any():\n",
    "                    loc_data[un_cluster].append([i*image_snips.shape[0] + j, i*image_snips.shape[0] + (j + 1)])\n",
    "        image_edges.append(loc_data)\n",
    "\n",
    "new_ie = []\n",
    "mappers = []\n",
    "nc = 0\n",
    "for i in range(len(image_edges)):\n",
    "    mappers.append({k:v+nc for v, k in enumerate(image_edges[i])})\n",
    "    nc += len(image_edges[i])\n",
    "\n",
    "assigner = {}\n",
    "for i, map_ in enumerate(mappers):\n",
    "    for key in map_:\n",
    "        assigner[(i, key)] = map_[key]\n",
    "    \n",
    "for i in range(len(image_edges)):\n",
    "    for j in image_edges[i]:\n",
    "        cont = image_edges[i][j]\n",
    "        new_ie.append([mappers[i][j], mappers[i][j]])\n",
    "        for item in cont:\n",
    "            new_ie.append([mappers[item[0]][j], mappers[item[1]][j]])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57951b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eaa65d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649173c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba6e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d2c6ea6",
   "metadata": {
    "id": "2d2c6ea6"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import TAGConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8acc5598",
   "metadata": {
    "id": "8acc5598"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import spspmm\n",
    "\n",
    "from torch_geometric.nn import GCNConv, TopKPooling, SAGPooling, BatchNorm\n",
    "\n",
    "from torch_geometric.utils.repeat import repeat\n",
    "\n",
    "def TagConv(channels):\n",
    "    return nn.ModuleList([TAGConv(channels, channels, 7, improved=True),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Dropout(0.0)])\n",
    "\n",
    "def StackedConv(channels, depth=3):\n",
    "    return nn.ModuleList([TagConv(channels) for _ in range(depth-1)] + [TAGConv(channels, channels, 7, improved=True)])\n",
    "class GraphUNet(torch.nn.Module):\n",
    "    r\"\"\"The Graph U-Net model from the `\"Graph U-Nets\"\n",
    "    <https://arxiv.org/abs/1905.05178>`_ paper which implements a U-Net like\n",
    "    architecture with graph pooling and unpooling operations.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample.\n",
    "        hidden_channels (int): Size of each hidden sample.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        depth (int): The depth of the U-Net architecture.\n",
    "        pool_ratios (float or [float], optional): Graph pooling ratio for each\n",
    "            depth. (default: :obj:`0.5`)\n",
    "        sum_res (bool, optional): If set to :obj:`False`, will use\n",
    "            concatenation for integration of skip connections instead\n",
    "            summation. (default: :obj:`True`)\n",
    "        act (torch.nn.functional, optional): The nonlinearity to use.\n",
    "            (default: :obj:`torch.nn.functional.relu`)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, depth,\n",
    "                 pool_ratios=0.5, sum_res=True, act=F.relu, reps=1):\n",
    "        super().__init__()\n",
    "        assert depth >= 1\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.depth = depth\n",
    "        self.pool_ratios = repeat(pool_ratios, depth)\n",
    "        self.act = act\n",
    "        self.sum_res = sum_res\n",
    "        self.reps = reps\n",
    "        self.limiter = nn.Parameter(torch.Tensor(np.zeros((1))), requires_grad=True)\n",
    "        channels = hidden_channels\n",
    "\n",
    "        self.down_convs = torch.nn.ModuleList()\n",
    "        self.pools = torch.nn.ModuleList()\n",
    "        \n",
    "        self.down_convs.append(TAGConv(in_channels, channels, 7, improved=True))\n",
    "        for rep in range(self.reps - 1):\n",
    "            self.down_convs.append(TAGConv(channels, channels, 7, improved=True))\n",
    "            self.down_convs.append(TAGConv(channels, channels, 7, improved=True))\n",
    "        for i in range(depth):\n",
    "            self.pools.append(TopKPooling(channels, self.pool_ratios[i]))\n",
    "            for rep in range(self.reps):\n",
    "                self.down_convs.append(TAGConv(channels, channels, 7, improved=True))\n",
    "\n",
    "\n",
    "\n",
    "        in_channels = channels if sum_res else 2 * channels\n",
    "\n",
    "        self.up_convs = torch.nn.ModuleList()\n",
    "        for i in range(depth - 1):\n",
    "            for rep in range(self.reps):\n",
    "                self.up_convs.append(TAGConv(channels, channels, 7, improved=True))\n",
    "            \n",
    "        for rep in range(self.reps - 1):\n",
    "            self.up_convs.append(TAGConv(channels, channels, 7, improved=True))\n",
    "        self.up_convs.append(TAGConv(in_channels, out_channels, 7, improved=True))\n",
    "        self.linear0 = nn.Linear(2, channels)\n",
    "        self.linear1 = nn.Linear(channels, channels)\n",
    "        self.linear2 = nn.Linear(channels, channels)\n",
    "        self.reset_parameters()\n",
    "        self.channels = channels\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.down_convs:\n",
    "            conv.reset_parameters()\n",
    "        for pool in self.pools:\n",
    "            pool.reset_parameters()\n",
    "        for conv in self.up_convs:\n",
    "            conv.reset_parameters()\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, startend, batch=None):\n",
    "        \"\"\"\"\"\"\n",
    "        if batch is None:\n",
    "            batch = edge_index.new_zeros(x.size(0))\n",
    "        edge_weight = x.new_ones(edge_index.size(1))\n",
    "        \n",
    "        x = self.down_convs[0](x, edge_index, edge_weight)\n",
    "        x = self.act(x)\n",
    "        for rep in range(1, self.reps):\n",
    "            x = self.down_convs[rep](x, edge_index, edge_weight)\n",
    "            x = self.act(x)\n",
    "\n",
    "        xs = [x]\n",
    "        edge_indices = [edge_index]\n",
    "        edge_weights = [edge_weight]\n",
    "        perms = []\n",
    "\n",
    "        for i in range(1, self.depth + 1):\n",
    "            edge_index, edge_weight = self.augment_adj(edge_index, edge_weight,\n",
    "                                                       x.size(0))\n",
    "            x, edge_index, edge_weight, batch, perm, _ = self.pools[i - 1](\n",
    "                x, edge_index, edge_weight, batch)\n",
    "            for rep in range(self.reps):\n",
    "                x = self.down_convs[rep + i*self.reps](x, edge_index, edge_weight)\n",
    "                x = self.act(x)\n",
    "\n",
    "            if i < self.depth:\n",
    "                xs += [x]\n",
    "                edge_indices += [edge_index]\n",
    "                edge_weights += [edge_weight]\n",
    "            perms += [perm]\n",
    "            \n",
    "        h = self.linear0(startend)\n",
    "        h = self.act(h)\n",
    "        h = self.linear1(h)\n",
    "        h = self.act(h)\n",
    "        h = self.linear2(h)\n",
    "        #print(x.shape)\n",
    "        h = h.squeeze(1)\n",
    "        #print(batch.shape, x.shape)\n",
    "        h = torch.gather(h, 0 , batch.unsqueeze(-1).repeat([1, self.channels]))\n",
    "        x = x + h\n",
    "        for i in range(self.depth):\n",
    "            j = self.depth - 1 - i\n",
    "\n",
    "            res = xs[j]\n",
    "            edge_index = edge_indices[j]\n",
    "            edge_weight = edge_weights[j]\n",
    "            perm = perms[j]\n",
    "\n",
    "            up = torch.zeros_like(res)\n",
    "            up[perm] = x\n",
    "            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n",
    "            \n",
    "            for rep in range(self.reps):\n",
    "                x = self.up_convs[rep + i*self.reps](x, edge_index, edge_weight)\n",
    "                x = x if ((i == self.depth-1) and (rep == self.reps-1)) else self.act(x)\n",
    "                #x =  if (i < self.depth - 1) else x\n",
    "            \n",
    "        x = x*self.limiter\n",
    "        return x\n",
    "\n",
    "\n",
    "    def augment_adj(self, edge_index, edge_weight, num_nodes):\n",
    "        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n",
    "        edge_index, edge_weight = add_self_loops(edge_index, edge_weight,\n",
    "                                                 num_nodes=num_nodes)\n",
    "        edge_index, edge_weight = sort_edge_index(edge_index, edge_weight,\n",
    "                                                  num_nodes)\n",
    "        edge_index, edge_weight = spspmm(edge_index, edge_weight, edge_index,\n",
    "                                         edge_weight, num_nodes, num_nodes,\n",
    "                                         num_nodes)\n",
    "        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n",
    "        return edge_index, edge_weight\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.hidden_channels}, {self.out_channels}, '\n",
    "                f'depth={self.depth}, pool_ratios={self.pool_ratios})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0e5b234",
   "metadata": {
    "id": "b0e5b234"
   },
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "038a70d6",
   "metadata": {
    "id": "038a70d6"
   },
   "outputs": [],
   "source": [
    "neighbor_filter = torch.zeros(1, 1, (2*(graph_size + 1)) + 1)\n",
    "neighbor_filter[:,:,1] = 1\n",
    "neighbor_filter[:,:,[graph_size, graph_size+2]] = 1\n",
    "neighbor_filter[:,:,(2*graph_size+1)] = 1\n",
    "neighbor_filter = neighbor_filter.to(device)\n",
    "\n",
    "neighbor_kernel = torch.zeros(1, 1, 3, 3)\n",
    "neighbor_kernel[:,:,:,1] = 1\n",
    "neighbor_kernel[:,:,1,:] = 1\n",
    "neighbor_kernel[:,:,1,1] = 0\n",
    "\n",
    "neighbor_kernel = neighbor_kernel.to(device)\n",
    "\n",
    "diff_kernel = torch.zeros(1, 1, 3, 3)\n",
    "diff_kernel[:,:,:,1] = 1\n",
    "diff_kernel[:,:,1,:] = 1\n",
    "diff_kernel[:,:,1,1] = 0\n",
    "\n",
    "diff_kernel = diff_kernel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fyeKpjHGVaiW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fyeKpjHGVaiW",
    "outputId": "52821051-0349-4109-d117-4c415889bcd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 1., 0.],\n",
       "          [1., 0., 1.],\n",
       "          [0., 1., 0.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbor_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ca2216e",
   "metadata": {
    "id": "1ca2216e"
   },
   "outputs": [],
   "source": [
    "def backtrack(start_maps: torch.tensor, goal_maps: torch.tensor,\n",
    "              parents: torch.tensor, current_t: int) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    Backtrack the search results to obtain paths\n",
    "    Args:\n",
    "        start_maps (torch.tensor): one-hot matrices for start locations\n",
    "        goal_maps (torch.tensor): one-hot matrices for goal locations\n",
    "        parents (torch.tensor): parent nodes\n",
    "        current_t (int): current time step\n",
    "    Returns:\n",
    "        torch.tensor: solution paths\n",
    "    \"\"\"\n",
    "\n",
    "    num_samples = start_maps.shape[0]\n",
    "    parents = parents.type(torch.long)\n",
    "    goal_maps = goal_maps.type(torch.long)\n",
    "    #start_maps = start_maps.type(torch.long)\n",
    "    path_maps = goal_maps.type(torch.long)\n",
    "    num_samples = len(parents)\n",
    "    loc = (parents * goal_maps.view(-1)).sum(-1)\n",
    "    for _ in range(current_t):\n",
    "        path_maps.view(-1)[loc] = 1\n",
    "        loc = parents[loc]\n",
    "    return path_maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d671c2",
   "metadata": {
    "id": "82d671c2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3aec68dc",
   "metadata": {
    "id": "3aec68dc"
   },
   "outputs": [],
   "source": [
    "def get_heuristic(goal: torch.tensor,\n",
    "                  size : torch.LongTensor,\n",
    "                  tb_factor: float = 0.001) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    Get heuristic function for A* search (chebyshev + small const * euclidean)\n",
    "    Args:\n",
    "        goal_maps (torch.tensor): one-hot matrices of goal locations\n",
    "        tb_factor (float, optional): small constant weight for tie-breaking. Defaults to 0.001.\n",
    "    Returns:\n",
    "        torch.tensor: heuristic function matrices\n",
    "    \"\"\"\n",
    "    idx = torch.arange(size, device=device)\n",
    "    rc = torch.remainder(idx, graph_size).unsqueeze(-1)\n",
    "    rr = torch.div(idx, graph_size, rounding_mode=\"floor\").unsqueeze(-1)\n",
    "    xy = torch.cat([rr, rc], axis=-1)\n",
    "    xy = xy.unsqueeze(0).repeat([goal.shape[0], 1, 1])\n",
    "    goal = goal.unsqueeze(1).repeat([1,xy.shape[1],1])\n",
    "    dxdy = torch.abs(xy - goal)\n",
    "    h = dxdy.sum(dim=-1) - dxdy.min(dim=-1)[0]\n",
    "    euc = torch.sqrt(((xy - goal)**2).sum(-1))\n",
    "    h = (euc)# + tb_factor * h)#.reshape_as(goal_maps)\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6435a582",
   "metadata": {
    "id": "6435a582"
   },
   "outputs": [],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d771933d",
   "metadata": {
    "id": "d771933d"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def _st_softmax_noexp(val: torch.tensor) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    Softmax + discretized activation\n",
    "    Used a detach() trick as done in straight-through softmax\n",
    "    Args:\n",
    "        val (torch.tensor): exponential of inputs.\n",
    "    Returns:\n",
    "        torch.tensor: one-hot matrices for input argmax.\n",
    "    \"\"\"\n",
    "\n",
    "    val_ = val\n",
    "    y = val_ / (val_.sum(dim=-1, keepdim=True))\n",
    "    _, ind = y.max(dim=-1)\n",
    "    y_hard = torch.zeros_like(y)\n",
    "    y_hard[range(y_hard.shape[0]), ind] = 1\n",
    "    y_hard = y_hard.reshape_as(val)\n",
    "    y = y.reshape_as(val)\n",
    "    return ((y_hard - y).detach() + y)\n",
    "\n",
    "def _st_softmax_noexp_ret(val: torch.tensor) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    Softmax + discretized activation\n",
    "    Used a detach() trick as done in straight-through softmax\n",
    "    Args:\n",
    "        val (torch.tensor): exponential of inputs.\n",
    "    Returns:\n",
    "        torch.tensor: one-hot matrices for input argmax.\n",
    "    \"\"\"\n",
    "\n",
    "    val_ = val\n",
    "    y = val_ / (val_.sum(dim=-1, keepdim=True))\n",
    "    _, ind = y.max(dim=-1)\n",
    "    y_hard = torch.zeros_like(y)\n",
    "    y_hard[range(y_hard.shape[0]), ind] = 1\n",
    "    y_hard = y_hard.reshape_as(val)\n",
    "    y = y.reshape_as(val)\n",
    "    return ((y_hard - y).detach() + y), y\n",
    "\n",
    "\n",
    "def expand(x: torch.tensor, neighbor_filter: torch.tensor) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    Expand neighboring node \n",
    "    Args:\n",
    "        x (torch.tensor): selected nodes\n",
    "        neighbor_filter (torch.tensor): 3x3 filter to indicate 8 neighbors\n",
    "    Returns:\n",
    "        torch.tensor: neighboring nodes of x\n",
    "    \"\"\"\n",
    "\n",
    "    x = x.unsqueeze(1)#.unsqueeze(0)\n",
    "    #num_samples = x.shape[1]\n",
    "    #print(x.shape, neighbor_filter.shape)\n",
    "    y = F.conv1d(x, neighbor_filter, padding=\"same\")#.squeeze(1)\n",
    "    y = y.squeeze(1)#.squeeze(0)\n",
    "    return y\n",
    "\n",
    "def expand2d(x: torch.tensor, neighbor_filter: torch.tensor) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    Expand neighboring node \n",
    "    Args:\n",
    "        x (torch.tensor): selected nodes\n",
    "        neighbor_filter (torch.tensor): 3x3 filter to indicate 8 neighbors\n",
    "    Returns:\n",
    "        torch.tensor: neighboring nodes of x\n",
    "    \"\"\"\n",
    "\n",
    "    x = x.unsqueeze(1)#.unsqueeze(0)\n",
    "    #num_samples = x.shape[1]\n",
    "    #print(x.shape, neighbor_filter.shape)\n",
    "    y = F.conv2d(x, neighbor_filter, padding=\"same\")#.squeeze(1)\n",
    "    y = y.squeeze(1)#.squeeze(0)\n",
    "    return y\n",
    "\n",
    "\n",
    "def find_path(cost_maps, start, end, img, back=True):\n",
    "    #cost_maps = out.squeeze(-1)*0\n",
    "\n",
    "    #self.open_maps *= 0\n",
    "    #self.goal_maps *= 0\n",
    "    #self.histories *= 0\n",
    "    #self.g *= 0\n",
    "    #self.stp *= 0\n",
    "    #self.stp += 1\n",
    "\n",
    "    start_maps = start#data.start#[:, 0]\n",
    "    goal_point = end#data.end#[:, 0]\n",
    "    obstacles_maps = img#data.x[:,0]#[:, 0]\n",
    "\n",
    "\n",
    "    num_samples = cost_maps.shape[0]\n",
    "    #neighbor_filter = self.neighbor_filter\n",
    "    #neighbor_filter = torch.repeat_interleave(neighbor_filter, num_samples,\n",
    "    #                                          0)\n",
    "    size = cost_maps.shape[1]\n",
    "    obstacles_maps = obstacles_maps.reshape(-1, size)\n",
    "    open_maps = torch.zeros_like(cost_maps)\n",
    "    open_maps[range(num_samples), start_maps] = 1\n",
    "    goal_maps = torch.zeros_like(cost_maps)#self.goal_maps\n",
    "    goal_maps[range(num_samples), goal_point] = 1\n",
    "    cost_maps = cost_maps.squeeze(-1)\n",
    "\n",
    "    histories = torch.zeros_like(cost_maps)#self.histories\n",
    "    intermediate_results = []\n",
    "\n",
    "    #h = co#torch.arange(size, device=device)*0 #self.get_heuristic(goal_maps)\n",
    "\n",
    "    goal = torch.cat([(end//graph_size).unsqueeze(1), (end%graph_size).unsqueeze(1)], axis=1)\n",
    "\n",
    "\n",
    "    h = get_heuristic(goal, size)\n",
    "    h = h * (1+(cost_maps)*1e-2)#.squeeze(-1)\n",
    "    g = torch.zeros_like(cost_maps)#self.g\n",
    "\n",
    "\n",
    "    parents = (torch.ones_like(cost_maps) * goal_maps.max(-1, keepdim=True)[-1])\n",
    "\n",
    "    training = True\n",
    "    Tmax = 1#0.25 if training else 1.\n",
    "    Tmax = int(Tmax * size)\n",
    "    g_ratio = 0.5\n",
    "\n",
    "    t_exp = 0\n",
    "\n",
    "    for t in range(Tmax):\n",
    "\n",
    "        # select the node that minimizes cost\n",
    "        #print(g.shape, h.shape)\n",
    "        f = g_ratio * g + (1 - g_ratio) * h\n",
    "        f_exp = torch.exp(-1 * f / size)\n",
    "        f_exp = f_exp * open_maps\n",
    "        selected_node_maps = _st_softmax_noexp(f_exp)\n",
    "        #print(selected_node_maps.shape)\n",
    "        #if store_intermediate_results:\n",
    "        #    intermediate_results.append({\n",
    "        #        \"histories\":\n",
    "        #        histories.unsqueeze(1).detach(),\n",
    "        #        \"paths\":\n",
    "        #        selected_node_maps.unsqueeze(1).detach()\n",
    "        #    })\n",
    "\n",
    "        # break if arriving at the goal\n",
    "        dist_to_goal = (selected_node_maps * goal_maps).sum(axis=-1, keepdim=True)\n",
    "        is_unsolved = (dist_to_goal < 1e-8).float()\n",
    "\n",
    "        histories = histories + selected_node_maps\n",
    "        histories = torch.clamp(histories, 0, 1)\n",
    "        open_maps = open_maps - is_unsolved * selected_node_maps\n",
    "        open_maps = torch.clamp(open_maps, 0, 1)\n",
    "\n",
    "        # open neighboring nodes, add them to the openlist if they satisfy certain requirements\n",
    "        #raise Exception()\n",
    "        #t1 = time.time()\n",
    "        gcpy = selected_node_maps.reshape(num_samples, graph_size, graph_size)\n",
    "        gcpy = F.pad(gcpy, (1, 1, 1, 1))#.reshape(num_samples, -1)\n",
    "        neighbor_nodes = expand2d(gcpy, neighbor_kernel)\n",
    "        #neighbor_nodes = neighbor_nodes.reshape(num_samples, graph_size+2, graph_size+2)\n",
    "        neighbor_nodes = neighbor_nodes[:, 1:-1, 1:-1].reshape(num_samples, -1)\n",
    "        neighbor_nodes = neighbor_nodes * obstacles_maps\n",
    "\n",
    "\n",
    "        # update g if one of the following conditions is met\n",
    "        # 1) neighbor is not in the close list (1 - histories) nor in the open list (1 - open_maps)\n",
    "        # 2) neighbor is in the open list but g < g2\n",
    "        cost_expand = (g + (cost_maps) * 1e-2) * selected_node_maps\n",
    "        cost_expand = cost_expand.reshape(num_samples, graph_size, graph_size)\n",
    "        cost_expand = F.pad(cost_expand, (1, 1, 1, 1))\n",
    "        cost_expand = expand2d(cost_expand, neighbor_kernel)\n",
    "        cost_expand = cost_expand[:, 1:-1, 1:-1].reshape(num_samples, -1)\n",
    "        g2 = cost_expand#expand(, neighbor_filter)\n",
    "        idx = (1 - open_maps) * (1 - histories) + open_maps * (g > g2)\n",
    "        idx = idx * neighbor_nodes\n",
    "        idx = idx.detach()\n",
    "        g = g2 * idx + g * (1 - idx)\n",
    "        g = g.detach()\n",
    "        # update open maps\n",
    "        open_maps = torch.clamp(open_maps + idx, 0, 1)\n",
    "        open_maps = open_maps.detach()\n",
    "\n",
    "        # for backtracking\n",
    "        idx = idx.reshape(num_samples, -1)\n",
    "        snm = selected_node_maps.reshape(num_samples, -1)\n",
    "        new_parents = snm.max(-1, keepdim=True)[-1]\n",
    "        #print(parents, new_parents * idx, idx.dtype)\n",
    "        parents = new_parents * idx + parents * (1 - idx)\n",
    "        if torch.all(is_unsolved.flatten() == 0):\n",
    "            break\n",
    "\n",
    "    if not back:\n",
    "        return histories, None\n",
    "    #t_e = time.time()\n",
    "    parents = parents.type(torch.long)\n",
    "    goal_maps = goal_maps.type(torch.long)\n",
    "    #start_maps = start_maps.type(torch.long)\n",
    "    path_maps = goal_maps.type(torch.long)\n",
    "    num_samples = len(parents)\n",
    "    loc = ((parents * goal_maps).sum(-1))\n",
    "    for _ in range(t):\n",
    "        path_maps[range(path_maps.shape[0]), loc] = 1\n",
    "        loc = parents[range(parents.shape[0]), loc]\n",
    "    #print(\"TIME BACKING: \", time.time() - t_e)\n",
    "    return histories, path_maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d38d007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import scatter\n",
    "from torch_geometric.nn import (MessageNorm, GraphNorm, PANPooling,\n",
    "ASAPooling, XConv, PointTransformerConv, PDNConv, PANConv, MessagePassing, GATv2Conv, EdgePooling)\n",
    "from torch_geometric.utils import softmax\n",
    "from torch.nn.init import xavier_normal_, zeros_\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "class Expander(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, k=3, dropout=0):\n",
    "        \"\"\"\n",
    "        coors - dimension of positional descriptors (e.g. 2 for 2D images)\n",
    "        in_channels - number of the input channels (node features)\n",
    "        out_channels - number of the output channels (node features)\n",
    "        hidden_size - number of the inner convolutions\n",
    "        dropout - dropout rate after the layer\n",
    "        \"\"\"\n",
    "        super().__init__(aggr='add')\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        x - feature matrix of the whole graph [num_nodes, label_dim]\n",
    "        pos - node position matrix [num_nodes, coors]\n",
    "        edge_index - graph connectivity [2, num_edges]\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.propagate(edge_index=edge_index, x=x, aggr='add') # [N, out_channels, label_dim]\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j\n",
    "\n",
    "def expand_graph(x, edge_index):\n",
    "    cur_x = scatter(x, edge_index[1], 1, reduce=\"add\")\n",
    "    return cur_x\n",
    "\n",
    "\n",
    "def find_path_graph(cost_maps, start, end, pos, edge_index, back=True):\n",
    "    #cost_maps = out.squeeze(-1)*0\n",
    "\n",
    "    #self.open_maps *= 0\n",
    "    #self.goal_maps *= 0\n",
    "    #self.histories *= 0\n",
    "    #self.g *= 0\n",
    "    #self.stp *= 0\n",
    "    #self.stp += 1\n",
    "\n",
    "    start_maps = start#data.start#[:, 0]\n",
    "    goal_point = end#data.end#[:, 0]\n",
    "    \n",
    "    \n",
    "    num_samples = cost_maps.shape[0]\n",
    "    #neighbor_filter = self.neighbor_filter\n",
    "    #neighbor_filter = torch.repeat_interleave(neighbor_filter, num_samples,\n",
    "    #                                          0)\n",
    "    size = cost_maps.shape[1]\n",
    "    open_maps = torch.zeros_like(cost_maps)\n",
    "    open_maps[range(num_samples), start_maps] = 1\n",
    "    goal_maps = torch.zeros_like(cost_maps)#self.goal_maps\n",
    "    goal_maps[range(num_samples), goal_point] = 1\n",
    "    cost_maps = cost_maps.squeeze(-1)\n",
    "\n",
    "    histories = torch.zeros_like(cost_maps)#self.histories\n",
    "    intermediate_results = []\n",
    "\n",
    "    #h = co#torch.arange(size, device=device)*0 #self.get_heuristic(goal_maps)\n",
    "\n",
    "    goal = torch.cat([(end//graph_size).unsqueeze(1), (end%graph_size).unsqueeze(1)], axis=1)\n",
    "\n",
    "\n",
    "    h = torch.sqrt(torch.square(goal-pos).sum(axis=-1))#get_heuristic(goal, size)\n",
    "    h = h * (1+(cost_maps)*1e-2)#.squeeze(-1)\n",
    "    g = torch.zeros_like(cost_maps)#self.g\n",
    "\n",
    "\n",
    "    parents = (torch.ones_like(cost_maps) * goal_maps.max(-1, keepdim=True)[-1])\n",
    "\n",
    "    training = True\n",
    "    Tmax = 1#0.25 if training else 1.\n",
    "    Tmax = int(Tmax * size)\n",
    "    g_ratio = 0.5\n",
    "\n",
    "    t_exp = 0\n",
    "\n",
    "    for t in range(Tmax):\n",
    "\n",
    "        # select the node that minimizes cost\n",
    "        #print(g.shape, h.shape)\n",
    "        f = g_ratio * g + (1 - g_ratio) * h\n",
    "        f_exp = torch.exp(-1 * f / size)\n",
    "        f_exp = f_exp * open_maps\n",
    "        selected_node_maps = _st_softmax_noexp(f_exp)\n",
    "        #print(selected_node_maps.shape)\n",
    "        #if store_intermediate_results:\n",
    "        #    intermediate_results.append({\n",
    "        #        \"histories\":\n",
    "        #        histories.unsqueeze(1).detach(),\n",
    "        #        \"paths\":\n",
    "        #        selected_node_maps.unsqueeze(1).detach()\n",
    "        #    })\n",
    "\n",
    "        # break if arriving at the goal\n",
    "        dist_to_goal = (selected_node_maps * goal_maps).sum(axis=-1, keepdim=True)\n",
    "        is_unsolved = (dist_to_goal < 1e-8).float()\n",
    "\n",
    "        histories = histories + selected_node_maps\n",
    "        histories = torch.clamp(histories, 0, 1)\n",
    "        open_maps = open_maps - is_unsolved * selected_node_maps\n",
    "        open_maps = torch.clamp(open_maps, 0, 1)\n",
    "\n",
    "        # open neighboring nodes, add them to the openlist if they satisfy certain requirements\n",
    "        #raise Exception()\n",
    "        #t1 = time.time()\n",
    "        neighbor_nodes = expand_graph(selected_node_maps, edge_index)\n",
    "        #neighbor_nodes = neighbor_nodes.reshape(num_samples, graph_size+2, graph_size+2)\n",
    "\n",
    "\n",
    "        # update g if one of the following conditions is met\n",
    "        # 1) neighbor is not in the close list (1 - histories) nor in the open list (1 - open_maps)\n",
    "        # 2) neighbor is in the open list but g < g2\n",
    "        cost_expand = (g + (cost_maps) * 1e-2) * selected_node_maps\n",
    "        cost_expand = expand_graph(cost_expand, edge_index)\n",
    "        g2 = cost_expand#expand(, neighbor_filter)\n",
    "        idx = (1 - open_maps) * (1 - histories) + open_maps * (g > g2)\n",
    "        idx = idx * neighbor_nodes\n",
    "        idx = idx.detach()\n",
    "        g = g2 * idx + g * (1 - idx)\n",
    "        g = g.detach()\n",
    "        # update open maps\n",
    "        open_maps = torch.clamp(open_maps + idx, 0, 1)\n",
    "        open_maps = open_maps.detach()\n",
    "\n",
    "        # for backtracking\n",
    "        idx = idx.reshape(num_samples, -1)\n",
    "        snm = selected_node_maps.reshape(num_samples, -1)\n",
    "        new_parents = snm.max(-1, keepdim=True)[-1]\n",
    "        #print(parents, new_parents * idx, idx.dtype)\n",
    "        parents = new_parents * idx + parents * (1 - idx)\n",
    "        if torch.all(is_unsolved.flatten() == 0):\n",
    "            break\n",
    "\n",
    "    if not back:\n",
    "        return histories, None\n",
    "    #t_e = time.time()\n",
    "    parents = parents.type(torch.long)\n",
    "    goal_maps = goal_maps.type(torch.long)\n",
    "    #start_maps = start_maps.type(torch.long)\n",
    "    path_maps = goal_maps.type(torch.long)\n",
    "    num_samples = len(parents)\n",
    "    loc = ((parents * goal_maps).sum(-1))\n",
    "    for _ in range(t):\n",
    "        path_maps[range(path_maps.shape[0]), loc] = 1\n",
    "        loc = parents[range(parents.shape[0]), loc]\n",
    "    #print(\"TIME BACKING: \", time.time() - t_e)\n",
    "    return histories, path_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55374739",
   "metadata": {
    "id": "55374739"
   },
   "outputs": [],
   "source": [
    "def find_path_cost(cost_maps, start, end, img, back=True):\n",
    "    #cost_maps = out.squeeze(-1)*0\n",
    "\n",
    "    #self.open_maps *= 0\n",
    "    #self.goal_maps *= 0\n",
    "    #self.histories *= 0\n",
    "    #self.g *= 0\n",
    "    #self.stp *= 0\n",
    "    #self.stp += 1\n",
    "\n",
    "    start_maps = start#data.start#[:, 0]\n",
    "    goal_point = end#data.end#[:, 0]\n",
    "    obstacles_maps = img#data.x[:,0]#[:, 0]\n",
    "\n",
    "\n",
    "    num_samples = cost_maps.shape[0]\n",
    "    #neighbor_filter = self.neighbor_filter\n",
    "    #neighbor_filter = torch.repeat_interleave(neighbor_filter, num_samples,\n",
    "    #                                          0)\n",
    "    size = cost_maps.shape[1]\n",
    "    obstacles_maps = obstacles_maps.reshape(-1, size)\n",
    "    open_maps = torch.zeros_like(cost_maps)\n",
    "    open_maps[range(num_samples), start_maps] = 1\n",
    "    open_maps.requires_grad_(True)\n",
    "    goal_maps = torch.zeros_like(cost_maps)#self.goal_maps\n",
    "    goal_maps[range(num_samples), goal_point] = 1\n",
    "    goal_maps.requires_grad_(True)\n",
    "    \n",
    "    cost_maps = cost_maps.squeeze(-1)\n",
    "\n",
    "    histories = torch.zeros_like(cost_maps, requires_grad=True)#self.histories\n",
    "    histories_y = torch.zeros_like(cost_maps, requires_grad=True)#self.histories\n",
    "    intermediate_results = []\n",
    "\n",
    "    #h = co#torch.arange(size, device=device)*0 #self.get_heuristic(goal_maps)\n",
    "\n",
    "    goal = torch.cat([(end//graph_size).unsqueeze(1), (end%graph_size).unsqueeze(1)], axis=1)\n",
    "\n",
    "\n",
    "    h = get_heuristic(goal, size)\n",
    "    h = h +  (1+(cost_maps))#.squeeze(-1)\n",
    "    g = torch.zeros_like(cost_maps)#self.g\n",
    "\n",
    "\n",
    "    parents = (torch.ones_like(cost_maps) * goal_maps.max(-1, keepdim=True)[-1])\n",
    "\n",
    "    training = True\n",
    "    Tmax = 1#0.25 if training else 1.\n",
    "    Tmax = int(Tmax * size)\n",
    "    g_ratio = 0.1\n",
    "\n",
    "    t_exp = 0\n",
    "\n",
    "    for t in range(Tmax):\n",
    "\n",
    "        # select the node that minimizes cost\n",
    "        #print(g.shape, h.shape)\n",
    "        f = g_ratio * g + (1 - g_ratio) * h\n",
    "        f_exp = torch.exp((f/size)) + 1e-5\n",
    "        f_exp = f_exp * open_maps\n",
    "        selected_node_maps, y_grid = _st_softmax_noexp_ret(f_exp)\n",
    "        if (y_grid < 0).any():\n",
    "            raise Exception(\"LESS THAN ZERO\")\n",
    "        histories_y = histories_y + torch.exp(y_grid) * open_maps\n",
    "        #print(selected_node_maps.shape)\n",
    "        #if store_intermediate_results:\n",
    "        #    intermediate_results.append({\n",
    "        #        \"histories\":\n",
    "        #        histories.unsqueeze(1).detach(),\n",
    "        #        \"paths\":\n",
    "        #        selected_node_maps.unsqueeze(1).detach()\n",
    "        #    })\n",
    "\n",
    "        # break if arriving at the goal\n",
    "        dist_to_goal = (selected_node_maps * goal_maps).sum(axis=-1, keepdim=True)\n",
    "        is_unsolved = (dist_to_goal < 1e-8).float()\n",
    "\n",
    "        histories = histories + selected_node_maps\n",
    "        histories = torch.clamp(histories, 0, 1)\n",
    "        open_maps = open_maps - is_unsolved * selected_node_maps\n",
    "        open_maps = torch.clamp(open_maps, 0, 1)\n",
    "\n",
    "        # open neighboring nodes, add them to the openlist if they satisfy certain requirements\n",
    "        #raise Exception()\n",
    "        #t1 = time.time()\n",
    "        gcpy = selected_node_maps.reshape(num_samples, graph_size, graph_size)\n",
    "        gcpy = F.pad(gcpy, (1, 1, 1, 1))#.reshape(num_samples, -1)\n",
    "        neighbor_nodes = expand2d(gcpy, neighbor_kernel)\n",
    "        #neighbor_nodes = neighbor_nodes.reshape(num_samples, graph_size+2, graph_size+2)\n",
    "        neighbor_nodes = neighbor_nodes[:, 1:-1, 1:-1].reshape(num_samples, -1)\n",
    "        neighbor_nodes = neighbor_nodes * obstacles_maps\n",
    "\n",
    "\n",
    "        # update g if one of the following conditions is met\n",
    "        # 1) neighbor is not in the close list (1 - histories) nor in the open list (1 - open_maps)\n",
    "        # 2) neighbor is in the open list but g < g2\n",
    "        cost_expand = (g + (cost_maps)) * selected_node_maps\n",
    "        cost_expand = cost_expand.reshape(num_samples, graph_size, graph_size)\n",
    "        cost_expand = F.pad(cost_expand, (1, 1, 1, 1))\n",
    "        cost_expand = expand2d(cost_expand, neighbor_kernel)\n",
    "        cost_expand = cost_expand[:, 1:-1, 1:-1].reshape(num_samples, -1)\n",
    "        g2 = cost_expand#expand(, neighbor_filter)\n",
    "        idx = (1 - open_maps) * (1 - histories) + open_maps * (g > g2)\n",
    "        idx = idx * neighbor_nodes\n",
    "        idx = idx.detach()\n",
    "        g = g2 * idx + g * (1 - idx)\n",
    "        g = g.detach()\n",
    "        # update open maps\n",
    "        open_maps = torch.clamp(open_maps + idx, 0, 1)\n",
    "        open_maps = open_maps.detach()\n",
    "\n",
    "        # for backtracking\n",
    "        idx = idx.reshape(num_samples, -1)\n",
    "        snm = selected_node_maps.reshape(num_samples, -1)\n",
    "        new_parents = snm.max(-1, keepdim=True)[-1]\n",
    "        #print(parents, new_parents * idx, idx.dtype)\n",
    "        parents = new_parents * idx + parents * (1 - idx)\n",
    "        if torch.all(is_unsolved.flatten() == 0):\n",
    "            break\n",
    "\n",
    "    if not back:\n",
    "        return histories, None\n",
    "    #t_e = time.time()\n",
    "    parents = parents.type(torch.long)\n",
    "    goal_maps = goal_maps.type(torch.long)\n",
    "    #start_maps = start_maps.type(torch.long)\n",
    "    path_maps = goal_maps.type(torch.long)\n",
    "    num_samples = len(parents)\n",
    "    loc = ((parents * goal_maps).sum(-1))\n",
    "    for _ in range(t):\n",
    "        path_maps[range(path_maps.shape[0]), loc] = 1\n",
    "        loc = parents[range(parents.shape[0]), loc]\n",
    "    #print(\"TIME BACKING: \", time.time() - t_e)\n",
    "    return histories, path_maps, histories_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5b17103",
   "metadata": {
    "id": "a5b17103"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    # Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)\n",
    "    def __init__(self, loss_fcn, gamma=2, alpha=0.75):\n",
    "        super().__init__()\n",
    "        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = loss_fcn.reduction\n",
    "        self.loss_fcn.reduction = 'none'  # required to apply FL to each element\n",
    "\n",
    "    def forward(self, pred, true):\n",
    "        loss = self.loss_fcn(pred, true)\n",
    "        # p_t = torch.exp(-loss)\n",
    "        # loss *= self.alpha * (1.000001 - p_t) ** self.gamma  # non-zero power for gradient stability\n",
    "\n",
    "        # TF implementation https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py\n",
    "        pred_prob = torch.sigmoid(pred)  # prob from logits\n",
    "        p_t = true * pred_prob + (1 - true) * (1 - pred_prob)\n",
    "        alpha_factor = true * self.alpha + (1 - true) * (1 - self.alpha)\n",
    "        modulating_factor = (1.0 - p_t) ** self.gamma\n",
    "        loss *= alpha_factor * modulating_factor\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:  # 'none'\n",
    "            return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e49fd18",
   "metadata": {
    "id": "8e49fd18"
   },
   "outputs": [],
   "source": [
    "import torch_geometric.nn as pyn\n",
    "\n",
    "class DiscreteSingleEdgeMessaging():\n",
    "    def __init__(self, in_channels, out_channels, k=3, dropout=0):\n",
    "        \"\"\"\n",
    "        coors - dimension of positional descriptors (e.g. 2 for 2D images)\n",
    "        in_channels - number of the input channels (node features)\n",
    "        out_channels - number of the output channels (node features)\n",
    "        hidden_size - number of the inner convolutions\n",
    "        dropout - dropout rate after the layer\n",
    "        \"\"\"\n",
    "        super(DiscreteSpatialGraphConv, self).__init__(aggr='add')\n",
    "        self.dropout = dropout\n",
    "        self.kernel_size = k\n",
    "        self.choice = Parameter((torch.rand((in_channels, 1, k,k))-0.5), requires_grad=True)\n",
    "        self.kernel = Parameter((torch.rand((in_channels, out_channels, k,k))-0.5), requires_grad=True)\n",
    "        \n",
    "        #self.bias = Parameter(torch.zeros((out_channels)), requires_grad=True)\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "    def forward(self, x, edge_index, pos):\n",
    "        \"\"\"\n",
    "        x - feature matrix of the whole graph [num_nodes, label_dim]\n",
    "        pos - node position matrix [num_nodes, coors]\n",
    "        edge_index - graph connectivity [2, num_edges]\n",
    "        \"\"\"\n",
    "        \n",
    "        print(edge_index, x.size(0))\n",
    "        edge_index, _ = remove_self_loops(edge_index, num_nodes=x.size(0))  # num_edges = num_edges + num_nodes\n",
    "        \n",
    "        return self.propagate(edge_index=edge_index, x=x, pos=pos, aggr='add')  # [N, out_channels, label_dim]\n",
    "    def message(self, pos_i, pos_j, x_j, x_i, edge_index):\n",
    "        \"\"\"\n",
    "        pos_i [num_edges, coors]\n",
    "        pos_j [num_edges, coors]\n",
    "        x_j [num_edges, label_dim]\n",
    "        \"\"\"\n",
    "        \n",
    "        edge_index = coalesce(edge_index, sort_by_row=False)\n",
    "        row, col = edge_index\n",
    "        \n",
    "        #x_i, x_j = x[row], x[col]\n",
    "        #pos_i, pos_j = pos[row], pos[col]\n",
    "        \n",
    "        relative_pos = pos_j - pos_i  # [n_edges, hidden_size * in_channels]\n",
    "        #print(\"dreiction:\", relative_pos.max(), relative_pos.min())\n",
    "\n",
    "        magnitude = (torch.abs(relative_pos).max(axis=-1)[0]).unsqueeze(-1) + 1e-5\n",
    "        direction = relative_pos / magnitude\n",
    "        is_self = (magnitude < 0.5).type(torch.int64)\n",
    "\n",
    "        \n",
    "        quantized = (torch.clip(torch.round(direction), -self.kernel_size//2, self.kernel_size//2) + self.kernel_size//2).type(torch.int64)* (1 - is_self) + is_self\n",
    "        \n",
    "        y_i = torch.einsum(\"ij, jki -> ik\", x_i, self.choice[:, :, 0, 0])# / torch.sqrt(1+magnitude)\n",
    "        y_j = torch.einsum(\"ij, jki -> ik\", x_j, self.choice[:, :, 0, 0])# / torch.sqrt(1+magnitude)\n",
    "        \n",
    "        ey = y_j - y_i\n",
    "        \n",
    "        \n",
    "        #print(\"result:\", result.shape)\n",
    "        #spatial_scaling = F.relu(self.lin_in(relative_pos))  # [n_edges, hidden_size * in_channels]\n",
    "\n",
    "        #n_edges = spatial_scaling.size(0)\n",
    "        # [n_edges, in_channels, ...] * [n_edges, in_channels, 1]\n",
    "        #result = spatial_scaling.reshape(n_edges, self.in_channels, -1) * x_j.unsqueeze(-1)\n",
    "        return result#result.view(n_edges, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fefe46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8f42073",
   "metadata": {
    "id": "c8f42073"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.utils import softmax\n",
    "\n",
    "class DiscreteSpatialGraphConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, k=3, dropout=0):\n",
    "        \"\"\"\n",
    "        coors - dimension of positional descriptors (e.g. 2 for 2D images)\n",
    "        in_channels - number of the input channels (node features)\n",
    "        out_channels - number of the output channels (node features)\n",
    "        hidden_size - number of the inner convolutions\n",
    "        dropout - dropout rate after the layer\n",
    "        \"\"\"\n",
    "        super().__init__(aggr='add')\n",
    "        self.dropout = dropout\n",
    "        self.kernel_size = k\n",
    "        self.kernel = Parameter(torch.Tensor(in_channels, in_channels, k, k), requires_grad=True)\n",
    "        self.bias = Parameter(torch.Tensor(out_channels), requires_grad=True)\n",
    "        self.kernel.retain_grad()\n",
    "        self.in_channels = in_channels\n",
    "        self.kernel = xavier_normal_(self.kernel)\n",
    "        self.bias = zeros_(self.bias)\n",
    "        print(self.kernel)\n",
    "    def forward(self, x, edge_index, pos):\n",
    "        \"\"\"\n",
    "        x - feature matrix of the whole graph [num_nodes, label_dim]\n",
    "        pos - node position matrix [num_nodes, coors]\n",
    "        edge_index - graph connectivity [2, num_edges]\n",
    "        \"\"\"\n",
    "        #print(edge_index, x.size(0))\n",
    "        #edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))  # num_edges = num_edges + num_nodes\n",
    "        #print(x.shape, pos.shape, edge_index.shape)\n",
    "        return self.propagate(edge_index=edge_index, x=x, pos=pos, aggr='add') + self.bias  # [N, out_channels, label_dim]\n",
    "\n",
    "    def message(self, pos, x_j):\n",
    "        \"\"\"\n",
    "        pos_i [num_edges, coors]\n",
    "        pos_j [num_edges, coors]\n",
    "        x_j [num_edges, label_dim]\n",
    "        \"\"\"\n",
    "        relative_pos = pos # [n_edges, hidden_size * in_channels]\n",
    "        #print(\"dreiction:\", relative_pos.max(), relative_pos.min())\n",
    "\n",
    "        magnitude = torch.sqrt((torch.square(relative_pos)).sum(axis=-1)).unsqueeze(-1) + 1e-5\n",
    "        direction = relative_pos / magnitude\n",
    "        is_self = (magnitude < 0.5).type(torch.int64)\n",
    "\n",
    "        \n",
    "        quantized = (torch.clip(torch.round(direction), -self.kernel_size//2, self.kernel_size//2) + self.kernel_size//2).type(torch.int64)* (1 - is_self) + is_self\n",
    "        quantized = quantized.detach()\n",
    "        #print(\"QUANT:\" ,quantized.shape, self.kernel[:, :, quantized[:,0], quantized[:,1]].shape)\n",
    "        #print(\"direction: \", direction, \"\\n rounded dir: \", torch.round(direction), \"\\n quant: \", quantized)\n",
    "        #raise Exception(\"\")\n",
    "        #print(x_j.shape, self.kernel[:, :, quantized[:,0], quantized[:,1]].shape)\n",
    "        result = torch.einsum(\"ij, jki -> ik\", x_j, self.kernel[:, :, quantized[:,0], quantized[:,1]])# / (1+magnitude)\n",
    "        \n",
    "        #ai = x_j.unsqueeze(1)\n",
    "        #bi = self.kernel[:, :, quantized[:,0], quantized[:,1]].permute(2, 0, 1)\n",
    "        #result = torch.bmm(ai, bi).squeeze(1)\n",
    "        #print(\"result:\", result.shape)\n",
    "        #spatial_scaling = F.relu(self.lin_in(relative_pos))  # [n_edges, hidden_size * in_channels]\n",
    "\n",
    "        #n_edges = spatial_scaling.size(0)\n",
    "        # [n_edges, in_channels, ...] * [n_edges, in_channels, 1]\n",
    "        #result = spatial_scaling.reshape(n_edges, self.in_channels, -1) * x_j.unsqueeze(-1)\n",
    "        return result#result.view(n_edges, -1)\n",
    "\n",
    "class DiscreteSpatialEdgeConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k=3, dropout=0):\n",
    "        \"\"\"\n",
    "        coors - dimension of positional descriptors (e.g. 2 for 2D images)\n",
    "        in_channels - number of the input channels (node features)\n",
    "        out_channels - number of the output channels (node features)\n",
    "        hidden_size - number of the inner convolutions\n",
    "        dropout - dropout rate after the layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.kernel_size = k\n",
    "        self.kernel = Parameter(torch.Tensor(in_channels, in_channels, k, k), requires_grad=True)\n",
    "        self.bias = Parameter(torch.Tensor(out_channels), requires_grad=True)\n",
    "        self.scaler = nn.Linear(in_channels*2, out_channels)\n",
    "        self.kernel.retain_grad()\n",
    "        self.in_channels = in_channels\n",
    "        self.kernel = xavier_normal_(self.kernel)\n",
    "        self.bias = zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x, edge_index, pos):\n",
    "        src, dst = edge_index\n",
    "        x_i, x_j = x[src], x[dst]\n",
    "        \n",
    "        \n",
    "        relative_pos = pos  # [n_edges, hidden_size * in_channels]\n",
    "        #print(\"dreiction:\", relative_pos.max(), relative_pos.min())\n",
    "\n",
    "        magnitude = torch.sqrt((torch.square(relative_pos)).sum(axis=-1)).unsqueeze(-1) + 1e-5\n",
    "        direction = relative_pos / magnitude\n",
    "        is_self = (magnitude < 0.5).type(torch.int64)\n",
    "\n",
    "        \n",
    "        quantized = (torch.clip(torch.round(direction), -self.kernel_size//2, self.kernel_size//2) + self.kernel_size//2).type(torch.int64)* (1 - is_self) + is_self\n",
    "        quantized = quantized.detach()\n",
    "        \n",
    "        x_i = torch.einsum(\"ij, jki -> ik\", x_i, self.kernel[:, :,\n",
    "                                                             self.kernel_size-quantized[:,0]-1,\n",
    "                                                             self.kernel_size-quantized[:,1]-1])\n",
    "        x_j = torch.einsum(\"ij, jki -> ik\", x_j, self.kernel[:, :,\n",
    "                                                             quantized[:,0],\n",
    "                                                             quantized[:,1]])\n",
    "        \n",
    "        x = self.scaler(torch.cat([x_i,x_j], axis=-1))\n",
    "        #print(edge_index, x.size(0))\n",
    "        #edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))  # num_edges = num_edges + num_nodes\n",
    "        #print(x.shape, pos.shape, edge_index.shape)\n",
    "        \n",
    "        \n",
    "        return softmax(x, src)\n",
    "\n",
    "class PathConvolution(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k=3, dropout=0):\n",
    "        \"\"\"\n",
    "        coors - dimension of positional descriptors (e.g. 2 for 2D images)\n",
    "        in_channels - number of the input channels (node features)\n",
    "        out_channels - number of the output channels (node features)\n",
    "        hidden_size - number of the inner convolutions\n",
    "        dropout - dropout rate after the layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.kernel_size = k\n",
    "        #self.kernel = Parameter(torch.Tensor(in_channels, in_channels, k, k), requires_grad=True)\n",
    "        #self.bias = Parameter(torch.Tensor(out_channels), requires_grad=True)\n",
    "        self.scaler = nn.Linear(in_channels*3, out_channels)\n",
    "        #self.kernel.retain_grad()\n",
    "        self.in_channels = in_channels\n",
    "        #self.kernel = xavier_normal_(self.kernel)\n",
    "        #self.bias = zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x, path_index):\n",
    "        src, mid, dst = path_index\n",
    "        x_i, x_m, x_j = x[src], x[mid], x[dst]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #degrees = degree(x_j)\n",
    "        #reps = torch.gather(degrees, 0, x_i)\n",
    "        #cur_x = scatter(torch.ones_like(x_j), x_j, 0, reduce=\"mean\")\n",
    "\n",
    "        #relative_pos = pos  # [n_edges, hidden_size * in_channels]\n",
    "        #print(\"dreiction:\", relative_pos.max(), relative_pos.min())\n",
    "\n",
    "        #magnitude = torch.sqrt((torch.square(relative_pos)).sum(axis=-1)).unsqueeze(-1) + 1e-5\n",
    "        #direction = relative_pos / magnitude\n",
    "        #is_self = (magnitude < 0.5).type(torch.int64)\n",
    "\n",
    "        \n",
    "        #quantized = (torch.clip(torch.round(direction), -self.kernel_size//2, self.kernel_size//2) + self.kernel_size//2).type(torch.int64)* (1 - is_self) + is_self\n",
    "        #quantized = quantized.detach()\n",
    "        \n",
    "        #x_i = torch.einsum(\"ij, jki -> ik\", x_i, self.kernel[:, :,\n",
    "        #                                                     self.kernel_size-quantized[:,0]-1,\n",
    "        #                                                     self.kernel_size-quantized[:,1]-1])\n",
    "        #x_j = torch.einsum(\"ij, jki -> ik\", x_j, self.kernel[:, :,\n",
    "        #                                                     quantized[:,0],\n",
    "        #                                                     quantized[:,1]])\n",
    "        \n",
    "        x0 = self.scaler(torch.cat([x_i, x_m, x_j], axis=-1))\n",
    "        x1 = self.scaler(torch.cat([x_j, x_m, x_i], axis=-1))\n",
    "        #print(edge_index, x.size(0))\n",
    "        #edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))  # num_edges = num_edges + num_nodes\n",
    "        #print(x.shape, pos.shape, edge_index.shape)\n",
    "        \n",
    "        \n",
    "        return x0 + x1#softmax(x, src)\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "class ScoredEdgePooling():\n",
    "    def __init__(self, min_score=0.1):\n",
    "        self.min_score = min_score\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, score, edge_index):\n",
    "        \n",
    "        return \n",
    "\n",
    "\n",
    "\n",
    "class DiscreteSingleMessageGraphConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, k=3, dropout=0):\n",
    "        \"\"\"\n",
    "        coors - dimension of positional descriptors (e.g. 2 for 2D images)\n",
    "        in_channels - number of the input channels (node features)\n",
    "        out_channels - number of the output channels (node features)\n",
    "        hidden_size - number of the inner convolutions\n",
    "        dropout - dropout rate after the layer\n",
    "        \"\"\"\n",
    "        super(DiscreteSingleMessageGraphConv, self).__init__(aggr='add')\n",
    "        self.dropout = dropout\n",
    "        self.kernel_size = k\n",
    "        self.choice = Parameter(data=(torch.rand((in_channels, 1, k,k))-0.5), requires_grad=True)\n",
    "        self.kernel = Parameter(data=(torch.rand((in_channels, out_channels, k,k))-0.5), requires_grad=True)\n",
    "        #self.bias = Parameter(torch.zeros((out_channels)), requires_grad=True)\n",
    "        self.in_channels = in_channels\n",
    "        self._score = None\n",
    "\n",
    "    def forward(self, x, pos, edge_index):\n",
    "        \"\"\"\n",
    "        x - feature matrix of the whole graph [num_nodes, label_dim]\n",
    "        pos - node position matrix [num_nodes, coors]\n",
    "        edge_index - graph connectivity [2, num_edges]\n",
    "        \"\"\"\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))  # num_edges = num_edges + num_nodes\n",
    "        out = self.propagate(edge_index=edge_index, x=x, pos=pos, aggr='add')\n",
    "        return out#, self._score  # [N, out_channels, label_dim]\n",
    "\n",
    "    def message(self, pos_i, pos_j, x_i, x_j, index, ptr, size_i):\n",
    "        \"\"\"\n",
    "        pos_i [num_edges, coors]\n",
    "        pos_j [num_edges, coors]\n",
    "        x_j [num_edges, label_dim]\n",
    "        \"\"\"\n",
    "        relative_pos = pos_j - pos_i\n",
    "\n",
    "        magnitude = (torch.abs(relative_pos).max(axis=-1)[0]).unsqueeze(-1) + 1e-5\n",
    "        direction = relative_pos / magnitude\n",
    "        is_self = (magnitude < 0.5).type(torch.int64)\n",
    "\n",
    "        \n",
    "        quantized = (torch.clip(torch.round(direction), -self.kernel_size//2, self.kernel_size//2) + self.kernel_size//2).type(torch.int64)* (1 - is_self) + is_self\n",
    "        \n",
    "\n",
    "\n",
    "        score = torch.einsum(\"ij, jki -> ik\", x_i+x_j, self.choice[:, :, quantized[:,0], quantized[:,1]])# / torch.sqrt(1+magnitude)\n",
    "        result = torch.einsum(\"ij, jki -> ik\", x_i+x_j, self.kernel[:, :, quantized[:,0], quantized[:,1]])# / torch.sqrt(1+magnitude)\n",
    "        alpha = softmax(score, index, ptr, size_i)\n",
    "        \n",
    "        self._score = score\n",
    "\n",
    "\n",
    "        return result * (alpha + 0.05)\n",
    "    \n",
    "class DiscreteSpatialGraphConv2(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, k=3, dropout=0):\n",
    "        \"\"\"\n",
    "        coors - dimension of positional descriptors (e.g. 2 for 2D images)\n",
    "        in_channels - number of the input channels (node features)\n",
    "        out_channels - number of the output channels (node features)\n",
    "        hidden_size - number of the inner convolutions\n",
    "        dropout - dropout rate after the layer\n",
    "        \"\"\"\n",
    "        super(DiscreteSpatialGraphConv2, self).__init__(aggr='add')\n",
    "        self.dropout = dropout\n",
    "        self.kernel_size = k\n",
    "        self.kernel = Parameter((torch.rand((in_channels, out_channels, k,k))-0.5), requires_grad=True)\n",
    "        #self.bias = Parameter(torch.zeros((out_channels)), requires_grad=True)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x, pos, edge_index):\n",
    "        \"\"\"\n",
    "        x - feature matrix of the whole graph [num_nodes, label_dim]\n",
    "        pos - node position matrix [num_nodes, coors]\n",
    "        edge_index - graph connectivity [2, num_edges]\n",
    "        \"\"\"\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))  # num_edges = num_edges + num_nodes\n",
    "        x = torch.einsum(\"ij, jkwh -> ikwh\", x, self.kernel).reshape(-1, self.out_channels*self.kernel_size*self.kernel_size)\n",
    "\n",
    "        return self.propagate(edge_index=edge_index, x=x, pos=pos, aggr='add')  # [N, out_channels, label_dim]\n",
    "\n",
    "    def message(self, pos_i, pos_j, x_j):\n",
    "        \"\"\"\n",
    "        pos_i [num_edges, coors]\n",
    "        pos_j [num_edges, coors]\n",
    "        x_j [num_edges, label_dim]\n",
    "        \"\"\"\n",
    "        x_j = x_j.reshape(-1, self.out_channels, self.kernel_size, self.kernel_size)\n",
    "        relative_pos = pos_j - pos_i  # [n_edges, hidden_size * in_channels]\n",
    "        #print(\"dreiction:\", relative_pos.max(), relative_pos.min())\n",
    "\n",
    "        magnitude = (torch.abs(relative_pos).max(axis=-1)[0]).unsqueeze(-1) + 1e-5\n",
    "        direction = relative_pos / magnitude\n",
    "        is_self = (magnitude < 0.5).type(torch.int64)\n",
    "\n",
    "        \n",
    "        quantized = (torch.clip(torch.round(direction), -self.kernel_size//2, self.kernel_size//2) + self.kernel_size//2).type(torch.int64)* (1 - is_self) + is_self\n",
    "        #print(\"QUANT:\" ,quantized.shape, self.kernel[:, :, quantized[:,0], quantized[:,1]].shape)\n",
    "        #print(direction, torch.round(direction), quantized)\n",
    "        #raise Exception(\"\")\n",
    "        result = x_j[:,:,quantized[:,0], quantized[:,1]]\n",
    "        \n",
    "        #print(\"result:\", result.shape)\n",
    "        #spatial_scaling = F.relu(self.lin_in(relative_pos))  # [n_edges, hidden_size * in_channels]\n",
    "\n",
    "        #n_edges = spatial_scaling.size(0)\n",
    "        # [n_edges, in_channels, ...] * [n_edges, in_channels, 1]\n",
    "        #result = spatial_scaling.reshape(n_edges, self.in_channels, -1) * x_j.unsqueeze(-1)\n",
    "        return result#result.view(n_edges, -1)\n",
    "\n",
    "\n",
    "def extract_image_patches(x, kernel, stride=1, dilation=1):\n",
    "    # Do TF 'SAME' Padding\n",
    "    b,c,h,w = x.shape\n",
    "    h2 = math.ceil(h / stride)\n",
    "    w2 = math.ceil(w / stride)\n",
    "    pad_row = (h2 - 1) * stride + (kernel - 1) * dilation + 1 - h\n",
    "    pad_col = (w2 - 1) * stride + (kernel - 1) * dilation + 1 - w\n",
    "    x = F.pad(x, (pad_row//2, pad_row - pad_row//2, pad_col//2, pad_col - pad_col//2))\n",
    "    \n",
    "    # Extract patches\n",
    "    patches = x.unfold(2, kernel, stride).unfold(3, kernel, stride)\n",
    "    patches = patches.permute(0,4,5,1,2,3).contiguous()\n",
    "    \n",
    "    return patches.view(b,-1,patches.shape[-2], patches.shape[-1])\n",
    "\n",
    "def hard_sigmoid(x):\n",
    "    det = ((x >= 0.5).type(x.dtype) - x).detach()\n",
    "    return x + det\n",
    "\n",
    "class Mapper(torch.nn.Module):\n",
    "    def __init__(self, channels=4, depth=5, reps=3, scalers = [], dropout=0.25):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        inp_channels = channels\n",
    "        self.conv1 = nn.Conv2d(1, channels, 3, padding=\"same\", bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "\n",
    "        self.depth = depth\n",
    "        self.reps = reps\n",
    "        self.cnv = []\n",
    "        self.bn = []\n",
    "        self.bttc = []\n",
    "        self.bttb = []\n",
    "        \n",
    "        for d in range(depth):\n",
    "            inchannels = channels\n",
    "            channels = channels#2 * channels\n",
    "            for rep in range(reps-1):\n",
    "                self.cnv.append(nn.Conv2d(inchannels, channels, 3, 1, padding=\"same\", bias=True))\n",
    "                self.bn.append(nn.BatchNorm2d(channels))\n",
    "                inchannels = channels\n",
    "            self.cnv.append(nn.Conv2d(inchannels, channels, 3, 1, dilation=2, padding=\"same\", bias=True))\n",
    "            self.bn.append(nn.BatchNorm2d(channels))\n",
    "        \n",
    "        \n",
    "        self.cnv_l = nn.Conv2d(channels, channels, 3, 1, padding=\"same\", bias=True)\n",
    "        self.bn_l = nn.BatchNorm2d(channels)\n",
    "        self.cnv = nn.ModuleList(self.cnv)\n",
    "        self.bn = nn.ModuleList(self.bn)\n",
    "        \n",
    "    def forward(self, x, training=True):\n",
    "        im = x\n",
    "        x = self.conv1(x)\n",
    "        #x = im * x\n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, self.dropout, training=training)\n",
    "        \n",
    "        \n",
    "        x = x\n",
    "        #self.scales = []\n",
    "        for d in range(self.depth):\n",
    "            #self.scales.append(x)\n",
    "            #h = x\n",
    "            for r in range(self.reps):\n",
    "                layer = self.cnv[d*self.reps+r]\n",
    "                x = layer(x)\n",
    "                #x = im * x\n",
    "                x = self.bn[d*self.reps+r](x)\n",
    "                x = F.leaky_relu(x)\n",
    "                x = F.dropout(x, self.dropout, training=training)\n",
    "            #x = F.max_pool2d(x, (2,2))\n",
    "            #x = h + x\n",
    "        x = self.cnv_l(x)\n",
    "        #x = im * x\n",
    "        x = self.bn_l(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, self.dropout, training=training)\n",
    "        return x\n",
    "\"\"\"\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, channels=32, depth=5, reps=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, channels, 3, padding=\"same\")\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        \n",
    "        self.reps = reps\n",
    "        self.depth = depth\n",
    "        self.channels = channels\n",
    "\n",
    "        self.convs = []\n",
    "        self.cbns = []\n",
    "\n",
    "        self.gcns = []\n",
    "        self.sagpool = []\n",
    "        \n",
    "        for rep in range(self.reps):\n",
    "            self.convs.append(nn.Conv2d(1, channels, 3, padding=\"same\"))\n",
    "            self.cbns.append(nn.BatchNorm2d(channels))\n",
    "        \n",
    "        for depth in range(self.depth):\n",
    "            for rep in range(self.reps):\n",
    "                self.gcns.append(GCNConv(channels, channels, improved=True))\n",
    "            self.sagpool.append(SAGPooling(channels, min_score=0.1))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def Convolution(in_channels, out_channels):\n",
    "    return PointTransformerConv(in_channels, out_channels)\n",
    "def Convolution2(in_channels, out_channels):\n",
    "    return PointTransformerConv(in_channels, out_channels)\n",
    "def FinalConvolution(in_channels, out_channels):\n",
    "    return PointTransformerConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "class Pather(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, depth,\n",
    "                 pool_ratios=0.25, sum_res=True, act=F.leaky_relu, reps=1):\n",
    "        super().__init__()\n",
    "        assert depth >= 1\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.depth = depth\n",
    "        self.pool_ratios = repeat(pool_ratios, depth)\n",
    "        self.act = act\n",
    "        self.sum_res = sum_res\n",
    "        self.reps = reps\n",
    "        self.limiter = nn.Parameter(torch.Tensor(np.zeros((1))), requires_grad=True)\n",
    "        channels = hidden_channels\n",
    "\n",
    "        self.down_convs = torch.nn.ModuleList()\n",
    "        self.down_bns = torch.nn.ModuleList()\n",
    "        self.pools = torch.nn.ModuleList()\n",
    "        \n",
    "        self.down_convs.append(Convolution(in_channels, channels))\n",
    "        self.down_bns.append(nn.BatchNorm1d(channels))\n",
    "        for rep in range(self.reps - 1):\n",
    "            self.down_convs.append(Convolution(channels, channels))\n",
    "            self.down_bns.append(nn.BatchNorm1d(channels))\n",
    "            \n",
    "        for i in range(depth):\n",
    "            self.pools.append(SAGPooling(channels, self.pool_ratios[i]))\n",
    "            for rep in range(self.reps):\n",
    "                self.down_convs.append(Convolution(channels, channels))\n",
    "                self.down_bns.append(nn.BatchNorm1d(channels))\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        in_channels = channels if sum_res else 2 * channels\n",
    "\n",
    "        self.up_convs = torch.nn.ModuleList()\n",
    "        self.up_bns = torch.nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            for rep in range(self.reps):\n",
    "                self.up_convs.append(Convolution(channels, channels))\n",
    "                self.up_bns.append(nn.BatchNorm1d(channels))\n",
    "            \n",
    "        for rep in range(self.reps - 1):\n",
    "            self.up_convs.append(Convolution2(channels, channels))\n",
    "            self.up_bns.append(nn.BatchNorm1d(channels))\n",
    "            \n",
    "        self.up_convs.append(FinalConvolution(channels, out_channels))\n",
    "        self.up_bns.append(nn.BatchNorm1d(out_channels))\n",
    "        #self.linear1 = nn.Linear(channels, channels)\n",
    "        #self.linear2 = nn.Linear(channels, channels)\n",
    "        #self.reset_parameters()\n",
    "        self.channels = channels\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.down_convs:\n",
    "            conv.reset_parameters()\n",
    "        for pool in self.pools:\n",
    "            pool.reset_parameters()\n",
    "        for conv in self.up_convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.up_bns:\n",
    "            bn.reset_parameters()\n",
    "        for bn in self.down_bns:\n",
    "            bn.reset_parameters()\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, batch=None, pos=None):\n",
    "        \"\"\"\"\"\"\n",
    "        if batch is None:\n",
    "            batch = edge_index.new_zeros(x.size(0))\n",
    "        edge_weight = x.new_ones(edge_index.size(1))\n",
    "        #print(x.shape)\n",
    "        x = self.down_convs[0](x, pos, edge_index)\n",
    "        #print(x.shape)\n",
    "        #print(\"POSITION\", pos)\n",
    "        x = self.down_bns[0](x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        for rep in range(1, self.reps):\n",
    "            h = x\n",
    "            x = self.down_convs[rep](x, pos, edge_index)\n",
    "            x = self.down_bns[rep](x)\n",
    "            x = self.act(x)\n",
    "            x = h + x\n",
    "        #\"\"\"\n",
    "        xs = [x]\n",
    "        edge_indices = [edge_index]\n",
    "        edge_weights = [edge_weight]\n",
    "        perms = []\n",
    "        pos_i = [pos]\n",
    "        batchs = [batch]\n",
    "        pos_x = pos\n",
    "        for i in range(1, self.depth + 1):\n",
    "            \n",
    "            #edge_index, edge_weight = self.augment_adj(edge_index, edge_weight,\n",
    "            #                                           x.size(0))\n",
    "            #print(x.shape, edge_index.shape)\n",
    "            x, edge_index, edge_weight, batch, perm, _ = self.pools[i - 1](\n",
    "                x, edge_index, edge_weight, batch)\n",
    "            #print(x.shape, edge_index.shape, batch.shape)\n",
    "            pos_x = pos_x[perm]\n",
    "            for rep in range(self.reps):\n",
    "                x = self.down_convs[rep + i*self.reps](x, pos_x, edge_index)\n",
    "                #print(x.shape)\n",
    "                x = self.down_bns[rep + i*self.reps](x)\n",
    "                x = self.act(x)\n",
    "\n",
    "            if i < self.depth:\n",
    "                xs += [x]\n",
    "                edge_indices += [edge_index]\n",
    "                edge_weights += [edge_weight]\n",
    "                pos_i += [pos_x]\n",
    "                batchs += [batch]\n",
    "            perms += [perm]\n",
    "            \n",
    "            \n",
    "        #h = self.linear0(startend)\n",
    "        #h = self.act(h)\n",
    "        #h = self.linear1(h)\n",
    "        #h = self.act(h)\n",
    "        #h = self.linear2(h)\n",
    "        #print(x.shape)\n",
    "        #h = h.squeeze(1)\n",
    "        #print(batch.shape, x.shape)\n",
    "        #h = torch.gather(h, 0 , batch.unsqueeze(-1).repeat([1, self.channels]))\n",
    "        #x = x + h\n",
    "        for i in range(self.depth):\n",
    "            j = self.depth - 1 - i\n",
    "            #print(x.shape, pos_x.shape, batch.shape)\n",
    "            print(x.shape, pos_x.shape)\n",
    "            for rep in range(self.reps):\n",
    "                x = self.up_convs[rep + i*self.reps](x, pos_x, edge_index)\n",
    "                x = self.up_bns[rep + i*self.reps](x)\n",
    "                x = self.act(x)\n",
    "            \n",
    "            #unp = perms[j]\n",
    "            #x, edge_index, batch = self.pools[j].unpool(x, unp)\n",
    "            res = xs[j]\n",
    "            edge_index = edge_indices[j]\n",
    "            edge_weight = edge_weights[j]\n",
    "            pos_x = pos_i[j]\n",
    "            perm = perms[j]\n",
    "            batch = batchs[j]\n",
    "\n",
    "            up = torch.zeros_like(res)\n",
    "            up[perm] = x\n",
    "            #up = x\n",
    "            \n",
    "            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n",
    "        \n",
    "        h = x\n",
    "        for rep in range(self.reps - 1):\n",
    "            x = self.up_convs[rep + self.depth*self.reps](x, pos, edge_index)#[0]\n",
    "            x = self.up_bns[rep + self.depth*self.reps](x)\n",
    "            x = self.act(x)\n",
    "        #\"\"\"\n",
    "        x = h + x\n",
    "        x = self.up_convs[-1](x, pos, edge_index)#[0]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def augment_adj(self, edge_index, edge_weight, num_nodes):\n",
    "        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n",
    "        edge_index, edge_weight = add_self_loops(edge_index, edge_weight,\n",
    "                                                 num_nodes=num_nodes)\n",
    "        edge_index, edge_weight = sort_edge_index(edge_index, edge_weight,\n",
    "                                                  num_nodes)\n",
    "        #print(edge_index, edge_weight, num_nodes)\n",
    "        edge_index, edge_weight = spspmm(edge_index, edge_weight, edge_index,\n",
    "                                         edge_weight, num_nodes, num_nodes,\n",
    "                                         num_nodes)\n",
    "        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n",
    "        return edge_index, edge_weight\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.hidden_channels}, {self.out_channels}, '\n",
    "                f'depth={self.depth}, pool_ratios={self.pool_ratios})')\n",
    "    \n",
    "def pos_2_direction(pos, edge_index):\n",
    "    return pos[edge_index[0, :]] - pos[edge_index[1, :]]\n",
    "\n",
    "def GraphNormalizer(channels):\n",
    "    return pyn.BatchNorm(channels)\n",
    "\n",
    "class Masker(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, depth,\n",
    "                 pool_ratios=0.25, sum_res=True, act=F.leaky_relu, reps=1, dropout=0.25):\n",
    "        super().__init__()\n",
    "        assert depth >= 1\n",
    "        self.dropout = dropout\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.depth = depth\n",
    "        self.pool_ratios = repeat(pool_ratios, depth)\n",
    "        self.act = act\n",
    "        if act is None:\n",
    "            self.act = torch.nn.Identity()\n",
    "        self.sum_res = sum_res\n",
    "        self.reps = reps\n",
    "        self.limiter = nn.Parameter(torch.Tensor(np.zeros((1))), requires_grad=True)\n",
    "        channels = hidden_channels\n",
    "\n",
    "        self.down_convs = torch.nn.ModuleList()\n",
    "        self.down_bns = torch.nn.ModuleList()\n",
    "        self.pools = torch.nn.ModuleList()\n",
    "        self.down_convs.append(Convolution(in_channels, channels))\n",
    "        self.down_bns.append(GraphNormalizer(channels))\n",
    "        in_chans = channels\n",
    "        for rep in range(self.reps - 1):\n",
    "            self.down_convs.append(Convolution(in_chans, channels))\n",
    "            self.down_bns.append(GraphNormalizer(channels))\n",
    "            in_chans = channels\n",
    "        channels = channels\n",
    "        for i in range(depth):\n",
    "            self.pools.append(ASAPooling(in_chans, self.pool_ratios[i]))\n",
    "            for rep in range(self.reps):\n",
    "                self.down_convs.append(Convolution(in_chans, channels))\n",
    "                print(i, in_chans, channels)\n",
    "                self.down_bns.append(GraphNormalizer(channels))\n",
    "                in_chans = channels\n",
    "            channels = channels#2 * channels\n",
    "                \n",
    "        channels = channels# // 2\n",
    "        #print(\"Res\", channels)\n",
    "\n",
    "        #in_channels = channels if sum_res else 2 * channels\n",
    "\n",
    "        self.up_convs = torch.nn.ModuleList()\n",
    "        self.up_bns = torch.nn.ModuleList()\n",
    "        inchannels = channels\n",
    "        for i in range(depth):\n",
    "            outchannels = inchannels# // 2\n",
    "            for rep in range(self.reps):\n",
    "                self.up_convs.append(Convolution(inchannels, outchannels))\n",
    "                print(i, inchannels, outchannels)\n",
    "                self.up_bns.append(GraphNormalizer(outchannels))\n",
    "                inchannels = outchannels\n",
    "            \n",
    "        for rep in range(self.reps - 1):\n",
    "            self.up_convs.append(Convolution2(outchannels, outchannels))\n",
    "            self.up_bns.append(GraphNormalizer(outchannels))\n",
    "            \n",
    "        self.up_convs.append(FinalConvolution(outchannels, out_channels))\n",
    "        self.up_bns.append(GraphNormalizer(out_channels))\n",
    "        \n",
    "        self.final_edge = DiscreteSpatialEdgeConv(outchannels, 1)\n",
    "        #self.linear1 = nn.Linear(channels, channels)\n",
    "        #self.linear2 = nn.Linear(channels, channels)\n",
    "        self.smd_conv = PathConvolution(out_channels, 1)\n",
    "        #self.reset_parameters()\n",
    "        self.channels = channels\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.down_convs:\n",
    "            conv.reset_parameters()\n",
    "        for pool in self.pools:\n",
    "            pool.reset_parameters()\n",
    "        for conv in self.up_convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.up_bns:\n",
    "            bn.reset_parameters()\n",
    "        for bn in self.down_bns:\n",
    "            bn.reset_parameters()\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, loc=None, edge_data=None, batch=None, smds=None, training=True):\n",
    "        \"\"\"\"\"\"\n",
    "        if batch is None:\n",
    "            batch = edge_index.new_zeros(x.size(0))\n",
    "        if edge_data is None:\n",
    "            edge_weight = x.new_ones(edge_index.size(1))\n",
    "        else:\n",
    "            edge_weight = edge_data\n",
    "        \n",
    "        if not loc is None:\n",
    "            if loc.shape[-1] == 2:\n",
    "                loc = F.pad(loc, (0,1))\n",
    "        #print(x.shape)\n",
    "        pos = pos_2_direction(loc, edge_index)\n",
    "        x = self.down_convs[0](x, loc, edge_index)\n",
    "        #print(x.shape)\n",
    "        #print(\"POSITION\", pos)\n",
    "        x = self.down_bns[0](x)\n",
    "        x = self.act(x)\n",
    "        h = x\n",
    "        for rep in range(1, self.reps):\n",
    "            #h = x\n",
    "            x = self.down_convs[rep](x, loc, edge_index)\n",
    "            x = self.down_bns[rep](x)\n",
    "            x = self.act(x)\n",
    "            x = F.dropout(x, self.dropout, training=training)\n",
    "        #x = h + x\n",
    "        #\"\"\"\n",
    "        xs = [x]\n",
    "        edge_indices = [edge_index]\n",
    "        edge_weights = [edge_weight]\n",
    "        edge_data = [edge_data]\n",
    "        locs = [loc]\n",
    "        perms = []\n",
    "        batchs = [batch]\n",
    "        for i in range(1, self.depth + 1):\n",
    "            \n",
    "            #edge_index, edge_weight = self.augment_adj(edge_index, edge_weight,\n",
    "            #                                           x.size(0))\n",
    "            #print(x.shape, edge_index.shape)\n",
    "            \n",
    "            x, edge_index, edge_weight, batch, perm = self.pools[i - 1](\n",
    "                x, edge_index, edge_weight, batch)\n",
    "            loc = loc[perm]\n",
    "            pos = pos_2_direction(loc, edge_index)\n",
    "            #print(x.shape, edge_index.shape, batch.shape)\n",
    "            for rep in range(self.reps):\n",
    "                x = self.down_convs[rep + i*self.reps](x, loc, edge_index)\n",
    "                #print(x.shape)\n",
    "                x = self.down_bns[rep + i*self.reps](x)\n",
    "                x = self.act(x)\n",
    "                x = F.dropout(x, self.dropout, training=training)\n",
    "\n",
    "            if i < self.depth:\n",
    "                #print(\"added\", x.shape)\n",
    "                xs += [x]\n",
    "                edge_indices += [edge_index]\n",
    "                edge_weights += [edge_weight]\n",
    "                batchs += [batch]\n",
    "                locs += [loc]\n",
    "            perms += [perm]\n",
    "            \n",
    "            \n",
    "        #h = self.linear0(startend)\n",
    "        #h = self.act(h)\n",
    "        #h = self.linear1(h)\n",
    "        #h = self.act(h)\n",
    "        #h = self.linear2(h)\n",
    "        #print(x.shape)\n",
    "        #h = h.squeeze(1)\n",
    "        #print(batch.shape, x.shape)\n",
    "        #h = torch.gather(h, 0 , batch.unsqueeze(-1).repeat([1, self.channels]))\n",
    "        #x = x + h\n",
    "        for i in range(self.depth):\n",
    "            j = -(i + 1) #self.depth - 1 - i\n",
    "            for rep in range(self.reps):\n",
    "                #print(x.shape, loc.shape, batch.shape)\n",
    "                x = self.up_convs[rep + i*self.reps](x, loc, edge_index)\n",
    "                x = self.up_bns[rep + i*self.reps](x)\n",
    "                x = self.act(x)\n",
    "                x = F.dropout(x, self.dropout, training=training)\n",
    "            \n",
    "            #unp = perms[j]\n",
    "            #x, edge_index, batch = self.pools[j].unpool(x, unp)\n",
    "            res = xs[j]\n",
    "            #print(res.shape, x.shape)\n",
    "            edge_index = edge_indices[j]\n",
    "            edge_weight = edge_weights[j]\n",
    "            perm = perms[j]\n",
    "            batch = batchs[j]\n",
    "            loc = locs[j]\n",
    "            pos = pos_2_direction(loc, edge_index)\n",
    "            up = torch.zeros_like(res)\n",
    "            up[perm] = x\n",
    "            #up = x\n",
    "            \n",
    "            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n",
    "        \n",
    "        h = x\n",
    "        for rep in range(self.reps - 1):\n",
    "            x = self.up_convs[rep + self.depth*self.reps](x, loc, edge_index)#[0]\n",
    "            x = self.up_bns[rep + self.depth*self.reps](x)\n",
    "            x = self.act(x)\n",
    "            x = F.dropout(x, self.dropout, training=training)\n",
    "        #\"\"\"\n",
    "        #x = h + x\n",
    "        x = self.up_convs[-1](x, loc, edge_index)#[0]\n",
    "        x = self.up_bns[-1](x)\n",
    "        #x = self.act(x)\n",
    "        #x = F.dropout(x, self.dropout, training=training)\n",
    "        edge_x = self.final_edge(x, edge_index, pos)\n",
    "        path_vals = None\n",
    "        if not (smds is None):\n",
    "            path_vals = self.smd_conv(x, smds)\n",
    "        x = self.max_edge(edge_x, edge_index)\n",
    "        \n",
    "        \n",
    "        return x, edge_x, path_vals\n",
    "    \n",
    "    def max_edge(self, x, edge_index):\n",
    "        src, dst = edge_index\n",
    "        x = scatter(x, dst, 0, reduce=\"mean\")\n",
    "        return x\n",
    "\n",
    "    def augment_adj(self, edge_index, edge_weight, num_nodes):\n",
    "        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n",
    "        edge_index, edge_weight = add_self_loops(edge_index, edge_weight,\n",
    "                                                 num_nodes=num_nodes)\n",
    "        edge_index, edge_weight = sort_edge_index(edge_index, edge_weight,\n",
    "                                                  num_nodes)\n",
    "        #print(edge_index, edge_weight, num_nodes)\n",
    "        edge_index, edge_weight = spspmm(edge_index, edge_weight, edge_index,\n",
    "                                         edge_weight, num_nodes, num_nodes,\n",
    "                                         num_nodes)\n",
    "        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n",
    "        return edge_index, edge_weight\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.hidden_channels}, {self.out_channels}, '\n",
    "                f'depth={self.depth}, pool_ratios={self.pool_ratios})')\n",
    "\n",
    "class CNNMasker(torch.nn.Module):\n",
    "    def __init__(self, channels=32, depth=5, reps=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depth = depth\n",
    "        self.reps = reps\n",
    "        \n",
    "        self.bttc = []\n",
    "        self.bttb = []\n",
    "        \n",
    "    \n",
    "        self.conv_query = nn.Conv2d(4, channels, 3, padding=\"same\", bias=False)\n",
    "        self.bn_q = nn.BatchNorm2d(channels)\n",
    "        \n",
    "        self.rem_depth = max([(int(np.log2(graph_size // (2**depth))) - 2), 0])\n",
    "\n",
    "        for rep in range(reps):\n",
    "            self.bttc.append(nn.Conv2d(channels, channels, 3, 1, padding=\"same\", bias=False))\n",
    "            self.bttb.append(nn.BatchNorm2d(channels))\n",
    "        \n",
    "        for d in range(self.rem_depth):\n",
    "            for rep in range(reps-1):\n",
    "                self.bttc.append(nn.Conv2d(channels, channels, 3, 1, padding=\"same\", bias=False))\n",
    "                self.bttb.append(nn.BatchNorm2d(channels))\n",
    "            self.bttc.append(nn.Conv2d(channels, channels, 3, 2, padding=1, bias=False))\n",
    "            self.bttb.append(nn.BatchNorm2d(channels))\n",
    "            \n",
    "        for d in range(self.rem_depth):\n",
    "            self.bttc.append(nn.ConvTranspose2d(channels, channels, 4, 2, padding=1, bias=False))\n",
    "            self.bttb.append(nn.BatchNorm2d(channels))\n",
    "            for rep in range(reps-1):\n",
    "                self.bttc.append(nn.Conv2d(channels, channels, 3, 1, padding=\"same\", bias=False))\n",
    "                self.bttb.append(nn.BatchNorm2d(channels))\n",
    "        \n",
    "        self.bttc.append(nn.Conv2d(channels, 1, 3, 1, padding=\"same\", bias=False))\n",
    "        self.bttb.append(nn.BatchNorm2d(1))\n",
    "        \n",
    "        self.bttc = nn.ModuleList(self.bttc)\n",
    "        self.bttb = nn.ModuleList(self.bttb)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, query):\n",
    "\n",
    "        q = self.conv_query(query)\n",
    "        #q = self.bn_q(q)\n",
    "        \n",
    "        x = x + q\n",
    "        #h = x\n",
    "        for r in range(self.reps):\n",
    "            x = self.bttc[r](x)\n",
    "            #x = self.bttb[r](x)\n",
    "            x = F.leaky_relu(x)\n",
    "            #print(r)\n",
    "        #x  = h + x\n",
    "        \n",
    "        a = x\n",
    "        splits = []\n",
    "        for r in range(self.rem_depth):\n",
    "            splits.append(a)\n",
    "            for d in range(self.reps):\n",
    "                #print(r, d, self.reps + r * self.reps + d)\n",
    "                a = self.bttc[self.reps+ r * self.reps + d](a)\n",
    "                #a = self.bttb[self.reps+ r * self.reps + d](a)\n",
    "                a = F.leaky_relu(a)\n",
    "            \n",
    "        for r in range(self.rem_depth):\n",
    "            for d in range(self.reps):\n",
    "                #print(r, d, self.reps + (rem_depth * self.reps) + r * self.reps + d)\n",
    "                a = self.bttc[self.reps + (self.rem_depth * self.reps) + r * self.reps + d](a)\n",
    "                #a = self.bttb[self.reps + (self.rem_depth * self.reps) + r * self.reps + d](a)\n",
    "                a = F.leaky_relu(a)\n",
    "            #print(a.shape, [split.shape for split in splits])\n",
    "            a = a + splits[-(r+1)]\n",
    "            #splits.append(a)\n",
    "        \n",
    "            \n",
    "            \n",
    "        a = self.bttc[-1](a)\n",
    "        #a = self.bttb[-1](a)\n",
    "        mask = torch.sigmoid(a)\n",
    "        mask = hard_sigmoid(mask)\n",
    "        #x = x * mask\n",
    "        \n",
    "        mask_up = mask\n",
    "        for d in range(self.depth):\n",
    "            mask_up = torch.repeat_interleave(torch.repeat_interleave(mask_up, 2, dim=2), 2, dim=3)\n",
    "        \n",
    "        return a, mask, mask_up\n",
    "    \n",
    "    \n",
    "    \n",
    "class CNNPather(torch.nn.Module):\n",
    "    def __init__(self, channels=32, depth=5, reps=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depth = depth\n",
    "        self.reps = reps\n",
    "        \n",
    "        self.bttc = []\n",
    "        self.bttb = []\n",
    "        \n",
    "    \n",
    "        self.conv_query = nn.Conv2d(3, channels, 3, padding=\"same\", bias=False)\n",
    "        self.bn_q = nn.BatchNorm2d(channels)\n",
    "        \n",
    "        for rep in range(reps):\n",
    "            self.bttc.append(nn.Conv2d(channels, channels, 3, 1, padding=\"same\", bias=False))\n",
    "            self.bttb.append(nn.BatchNorm2d(channels))\n",
    "        \n",
    "        for d in range(self.depth):\n",
    "            for rep in range(reps-1):\n",
    "                self.bttc.append(nn.Conv2d(channels, channels, 3, 1, padding=\"same\", bias=False))\n",
    "                self.bttb.append(nn.BatchNorm2d(channels))\n",
    "            self.bttc.append(nn.Conv2d(channels, channels, 3, 2, padding=1, bias=False))\n",
    "            self.bttb.append(nn.BatchNorm2d(channels))\n",
    "            \n",
    "        for d in range(self.depth):\n",
    "            self.bttc.append(nn.ConvTranspose2d(channels, channels, 4, 2, padding=1, bias=False))\n",
    "            self.bttb.append(nn.BatchNorm2d(channels))\n",
    "            for rep in range(reps-1):\n",
    "                self.bttc.append(nn.Conv2d(channels, channels, 3, 1, padding=\"same\", bias=False))\n",
    "                self.bttb.append(nn.BatchNorm2d(channels))\n",
    "        \n",
    "        self.bttc.append(nn.Conv2d(channels, 1, 3, 1, padding=\"same\", bias=False))\n",
    "        self.bttb.append(nn.BatchNorm2d(1))\n",
    "        \n",
    "        self.bttc = nn.ModuleList(self.bttc)\n",
    "        self.bttb = nn.ModuleList(self.bttb)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_query(x)\n",
    "        x = self.bn_q(x)\n",
    "        #h = x\n",
    "        for r in range(self.reps):\n",
    "            x = self.bttc[r](x)\n",
    "            x = self.bttb[r](x)\n",
    "            x = F.leaky_relu(x)\n",
    "            #print(r)\n",
    "        #x  = h + x\n",
    "        \n",
    "        a = x\n",
    "        splits = []\n",
    "        for r in range(self.depth):\n",
    "            splits.append(a)\n",
    "            for d in range(self.reps):\n",
    "                #print(r, d, self.reps + r * self.reps + d)\n",
    "                a = self.bttc[self.reps+ r * self.reps + d](a)\n",
    "                a = self.bttb[self.reps+ r * self.reps + d](a)\n",
    "                a = F.leaky_relu(a)\n",
    "            \n",
    "        for r in range(self.depth):\n",
    "            for d in range(self.reps):\n",
    "                #print(r, d, self.reps + (rem_depth * self.reps) + r * self.reps + d)\n",
    "                a = self.bttc[self.reps + (self.depth * self.reps) + r * self.reps + d](a)\n",
    "                a = self.bttb[self.reps + (self.depth * self.reps) + r * self.reps + d](a)\n",
    "                a = F.leaky_relu(a)\n",
    "            #print(a.shape, [split.shape for split in splits])\n",
    "            a = a + splits[-(r+1)]\n",
    "            #splits.append(a)\n",
    "        \n",
    "            \n",
    "            \n",
    "        a = self.bttc[-1](a)\n",
    "        \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "M2p6TXPY5TWJ",
   "metadata": {
    "id": "M2p6TXPY5TWJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.LongTensor(np.random.randint(0, 10, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c26c1bd4",
   "metadata": {
    "id": "c26c1bd4"
   },
   "outputs": [],
   "source": [
    "degrees = degree(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cf91a76",
   "metadata": {
    "id": "4cf91a76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1, 0, 9, 7, 7, 1, 7, 9, 8, 3, 7, 0, 4, 1, 4, 5, 6, 7, 1, 2, 6, 0,\n",
       "        4, 8, 1, 9, 8, 8, 0, 1, 3, 7, 1, 7, 4, 7, 7, 3, 2, 9, 7, 1, 1, 4, 9, 8,\n",
       "        8, 7, 1, 9, 5, 0, 0, 2, 4, 6, 8, 4, 8, 6, 7, 6, 6, 4, 9, 5, 6, 5, 5, 9,\n",
       "        7, 0, 9, 2, 4, 3, 0, 8, 6, 6, 9, 8, 7, 0, 5, 0, 0, 6, 6, 2, 0, 2, 2, 9,\n",
       "        7, 9, 8, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1e5c9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1, 0, 9, 7, 7, 1, 7, 9, 8, 3, 7, 0, 4, 1, 4, 5, 6, 7, 1, 2, 6, 0,\n",
       "        4, 8, 1, 9, 8, 8, 0, 1, 3, 7, 1, 7, 4, 7, 7, 3, 2, 9, 7, 1, 1, 4, 9, 8,\n",
       "        8, 7, 1, 9, 5, 0, 0, 2, 4, 6, 8, 4, 8, 6, 7, 6, 6, 4, 9, 5, 6, 5, 5, 9,\n",
       "        7, 0, 9, 2, 4, 3, 0, 8, 6, 6, 9, 8, 7, 0, 5, 0, 0, 6, 6, 2, 0, 2, 2, 9,\n",
       "        7, 9, 8, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7ee2dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13., 11.,  8.,  4.,  9.,  6., 11., 15., 11., 12.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4653840",
   "metadata": {
    "id": "f4653840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8 8\n",
      "0 8 8\n",
      "0 8 8\n",
      "1 8 8\n",
      "1 8 8\n",
      "1 8 8\n",
      "0 8 8\n",
      "0 8 8\n",
      "0 8 8\n",
      "1 8 8\n",
      "1 8 8\n",
      "1 8 8\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall\n",
    "\n",
    "chunk_filters = [torch.ones(1, 1, red, red).to(device) for red in reduction_rate]\n",
    "\n",
    "encoders = [Mapper(channels=8, depth=d, reps=3).to(device) for d in depth]\n",
    "maskers = [Masker(in_channels=10, hidden_channels=8, out_channels=8, depth=d, reps=3).to(device) for d in depth]\n",
    "\n",
    "\n",
    "#encoder = Mapper(channels=8, depth=depth[0], reps=2).to(device)\n",
    "\n",
    "#pather = CNNPather(channels=128, depth=depth, reps=5).to(device)\n",
    "#pather = Pather(in_channels=10, hidden_channels=8, out_channels=1, depth=2, reps=2).to(device)\n",
    "\n",
    "acc = BinaryAccuracy(threshold=0.5, validate_args=False).to(device)\n",
    "pres = BinaryPrecision(threshold=0.5, validate_args=False).to(device)\n",
    "rec = BinaryRecall(threshold=0.5, validate_args=False).to(device)\n",
    "\n",
    "l1_func = nn.L1Loss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3d04500",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3d04500",
    "outputId": "058f75cc-8367-4abd-caaa-f538cd62aaed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous weights!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mapper.load_state_dict(torch.load(\"mapper.pt\"))\n",
    "    decoder.load_state_dict(torch.load(\"decoder.pt\"))\n",
    "except:\n",
    "    print(\"No previous weights!\")\n",
    "loss_chunk = FocalLoss(torch.nn.BCEWithLogitsLoss(reduction=\"none\")).to(device)\n",
    "loss_func = FocalLoss(torch.nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([1]), reduction=\"none\")).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cLpU4SEo2y8i",
   "metadata": {
    "id": "cLpU4SEo2y8i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e0d78d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "66e0d78d",
    "outputId": "a24ae969-525b-4a57-c156-d7a74b9a6a92",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Troll_000\\AppData\\Roaming\\Python\\Python38\\site-packages\\pymastar2d\\mastar_wrapper.py:79: Warning: BREAKING\n",
      "  path = pymastar2d.mastar.mastar(\n",
      "64it [10:33,  9.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Chunk: 0 Time: 633.01     Loss: 0.1734     MPL: 0.0498     Precision: 1.00 Recall: 0.08     Scored Path: 0.995     Masked Path: 0.965     A* Masked Path: 0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [10:47, 10.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Chunk: 1 Time: 647.19     Loss: 0.1932     MPL: 0.0314     Precision: 1.00 Recall: 0.08     Scored Path: 0.994     Masked Path: 0.960     A* Masked Path: 0.940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [10:35,  9.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Chunk: 2 Time: 635.19     Loss: 0.1736     MPL: 0.0309     Precision: 1.00 Recall: 0.09     Scored Path: 0.994     Masked Path: 0.965     A* Masked Path: 0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [10:52, 10.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Chunk: 3 Time: 652.76     Loss: 0.1774     MPL: 0.0296     Precision: 1.00 Recall: 0.08     Scored Path: 0.994     Masked Path: 0.964     A* Masked Path: 0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [11:00, 10.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Chunk: 4 Time: 660.97     Loss: 0.1849     MPL: 0.0298     Precision: 1.00 Recall: 0.09     Scored Path: 0.994     Masked Path: 0.964     A* Masked Path: 0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [10:32,  9.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Chunk: 5 Time: 632.21     Loss: 0.1837     MPL: 0.0294     Precision: 1.00 Recall: 0.09     Scored Path: 0.993     Masked Path: 0.963     A* Masked Path: 0.940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [10:17,  9.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Chunk: 6 Time: 617.97     Loss: 0.1827     MPL: 0.0293     Precision: 1.00 Recall: 0.10     Scored Path: 0.995     Masked Path: 0.964     A* Masked Path: 0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [10:52, 10.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Chunk: 7 Time: 652.59     Loss: 0.1672     MPL: 0.0290     Precision: 1.00 Recall: 0.09     Scored Path: 0.995     Masked Path: 0.966     A* Masked Path: 0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [08:20,  8.66s/it]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torchvision.transforms.functional as VF\n",
    "from tqdm import tqdm\n",
    "from pyastar2d import astar_path\n",
    "from pymastar2d import mastar_path\n",
    "\n",
    "def generate_goal(img, start, end, reduction_rate):\n",
    "    startrel = (start%reduction_rate)/reduction_rate\n",
    "    endrel = (end%reduction_rate)/reduction_rate\n",
    "    startr = start // reduction_rate\n",
    "    endr = end // reduction_rate\n",
    "    startrel = startrel.reshape(-1, 2)\n",
    "    endrel = endrel.reshape(-1, 2)\n",
    "    startr = startr.reshape(-1, 2)\n",
    "    endr = endr.reshape(-1, 2)\n",
    "\n",
    "    goal_map = torch.zeros((img.shape[0]*NUM_PATHS, 4,\n",
    "                        img.shape[2]//(reduction_rate),\n",
    "                        img.shape[3]//(reduction_rate)))\n",
    "    #for p in range(NUM_PATHS):\n",
    "    goal_map[range(img.shape[0] * NUM_PATHS), :2, startr[:,0], startr[:,1]] += startrel\n",
    "    goal_map[range(img.shape[0] * NUM_PATHS), :2, endr[:,0], endr[:,1]] += endrel\n",
    "    goal_map[range(img.shape[0] * NUM_PATHS), 2, startr[:,0], startr[:,1]] += 1#startrel\n",
    "    goal_map[range(img.shape[0] * NUM_PATHS), 3, endr[:,0], endr[:,1]] += 1#endrel\n",
    "    goal_map = goal_map.to(device)\n",
    "    return goal_map\n",
    "def reduce_graph(edge_index):\n",
    "    valid_nodes = edge_index[0]\n",
    "    unique_nodes = np.unique(edge_index)\n",
    "    mp = np.arange(np.max(unique_nodes)+1)\n",
    "    new_nodes = np.zeros_like(edge_index)\n",
    "    key = np.arange(unique_nodes.shape[0])\n",
    "    mp[unique_nodes] = key\n",
    "    new_nodes[0,:] = mp[edge_index[0]]\n",
    "    new_nodes[1,:] = mp[edge_index[1]]\n",
    "    return new_nodes, unique_nodes\n",
    "\n",
    "import time\n",
    "%matplotlib inline  \n",
    "optimizer = torch.optim.Adam(sum([list(encoder.parameters()) for encoder in encoders], []) +\n",
    "                                sum([list(masker.parameters()) for masker in maskers], []), lr=1e-2)\n",
    "#\n",
    "#optimizer2 = torch.optim.RMSprop(list(encoder.parameters()) + list(pather.parameters()), lr=1e-3)\n",
    "\n",
    "def data_list_batch(data):\n",
    "    dat = []\n",
    "    edge_list = []\n",
    "    batch = []\n",
    "    edge_data = []\n",
    "    smds = []\n",
    "    en = 0\n",
    "    for i, d in enumerate(data):\n",
    "        dat.append(d.x)\n",
    "        edge_list.append(d.edge_index + en)\n",
    "        edge_data.append(d.edge_data)\n",
    "        smds.append(d.smds + en)\n",
    "        en += d.x.shape[0]\n",
    "        batch_dim = (torch.zeros((d.x.shape[0]), dtype=torch.int64) + i)\n",
    "        batch.append(batch_dim)\n",
    "        \n",
    "    return Data(x=torch.cat(dat, axis=0).to(device),\n",
    "                edge_index=torch.cat(edge_list, axis=0).to(device),\n",
    "                batch=torch.cat(batch, axis=0).to(device),\n",
    "                edge_data = torch.cat(edge_data, axis=0).to(device),\n",
    "                smds = torch.cat(smds, axis=0).to(device))\n",
    "\n",
    "def batch_list_data(x, batch):\n",
    "    dat = []\n",
    "    for i in range(batch.max()+1):\n",
    "        dat.append(x[batch==i])\n",
    "        \n",
    "    return dat\n",
    "def nodedist(a, b):\n",
    "    (x1, y1) = a//graph_size, a % graph_size\n",
    "    (x2, y2) = b//graph_size, b % graph_size\n",
    "    return (((x1 - x2) ** 2 + (y1 - y2) ** 2) ** 0.5)\n",
    "def wrapped_nodedist(pos_list):\n",
    "    \n",
    "    def _nodedist(a, b):\n",
    "        (x1, y1) = a//graph_size, a % graph_size\n",
    "        (x2, y2) = b//graph_size, b % graph_size\n",
    "        return ((x1 - x2) ** 2 + (y1 - y2) ** 2) ** 0.5\n",
    "    return _nodedist\n",
    "encoders[0].dropout = 0.1\n",
    "maskers[0].dropout = 0.1\n",
    "#find_path = ASTAR(8, graph_size)\n",
    "graph_sqr = graph_size * graph_size\n",
    "def visualize(data=None, start=None, end=None, path=None, history=None):\n",
    "\n",
    "    map = np.zeros((graph_size*graph_size, 3))\n",
    "    #edges = data.edge_index[0,:]\n",
    "    #edges = edges[edges<(graph_size*graph_size)]\n",
    "    #map[edges, :] = 1\n",
    "    data = data.reshape(-1, 1)\n",
    "    map[:,:] = data\n",
    "    #print(path.shape, history.shape, data.x[:graph_size*graph_size].shape)\n",
    "    path = path * data[:,0]\n",
    "    history = history * data[:,0]\n",
    "    empty_map = map[:,:1]\n",
    "    map[path>0] = [0,0,0]\n",
    "\n",
    "    history = history>0.5\n",
    "    map[history] = [1,0.5,0]\n",
    "\n",
    "    map[path>0] = map[path>0] + [0, 0.5, 0]\n",
    "\n",
    "    #map = map * (empty_map)\n",
    "    \n",
    "\n",
    "    map = map.reshape(graph_size, graph_size, 3)\n",
    "    \n",
    "    map[start[0], start[1], :] = [0, 0, 1]\n",
    "    map[end[0], end[1], :] = [1, 0, 0]\n",
    "    map = np.clip(map, 0, 1)\n",
    "    \n",
    "    return map\n",
    "\n",
    "#model.train()\n",
    "buffer = []\n",
    "noise_effect = 1\n",
    "for epoch in range(20000):\n",
    "    tepoch = time.time()\n",
    "    lss_accum = 0\n",
    "    lssc_accum = 0\n",
    "    acc_accum = 0\n",
    "    pres_accum = 0\n",
    "    pres_base = 0\n",
    "    rec_accum = 0\n",
    "    acc_accum1 = 0\n",
    "    pres_accum1 = 0\n",
    "    rec_accum1 = 0\n",
    "    path_lss = 0\n",
    "    path_lens = []\n",
    "    path_olen = []\n",
    "    path_nosc = []\n",
    "    path_pure = []\n",
    "    interfaces = []\n",
    "    #if len(buffer) < 100:\n",
    "    for idx, batch in tqdm(enumerate(train_loader)):\n",
    "        loss = 0\n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        t0 = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        #optimizer2.zero_grad()\n",
    "        #with torch.autocast(\"cuda\"):\n",
    "        img = batch[0].to(device)\n",
    "        start = batch[1]#.to(device)\n",
    "        end = batch[2]#.to(device)\n",
    "        labels = batch[3].numpy()\n",
    "        labels2 = batch[4].numpy()\n",
    "        assigners = []\n",
    "        new_ies = []\n",
    "        smds = [] \n",
    "        mapperss = []\n",
    "        new_pos = []\n",
    "        interfaces = []\n",
    "        \n",
    "        for l, label in enumerate(labels):\n",
    "            image_snips = np.zeros((enc_size[0], enc_size[0], reduction_rate[0], reduction_rate[0]))\n",
    "            image_edges = []\n",
    "            interface = {}\n",
    "            dat = []\n",
    "            for i in range(image_snips.shape[0]):\n",
    "                for j in range(image_snips.shape[0]):\n",
    "                    image_snips[i,j] = label[image_snips.shape[2]*i:image_snips.shape[2]*(i+1),\n",
    "                                             image_snips.shape[2]*j:image_snips.shape[2]*(j+1), 0]\n",
    "\n",
    "            nc = 0        \n",
    "            for i in range(image_snips.shape[0]):\n",
    "                for j in range(image_snips.shape[0]): \n",
    "                    loc_data = {}\n",
    "                    for uc, un_cluster in enumerate(np.unique(image_snips[i,j].flatten()).astype(np.int32)):\n",
    "                        interface[un_cluster] = {\"info\": [i, j]}\n",
    "                        dat = [i,j]\n",
    "                        if un_cluster == 0:\n",
    "                            continue\n",
    "                        loc_data[un_cluster] = []\n",
    "                        if i > 0:\n",
    "                            filt = image_snips[i,j, 0, :] == un_cluster\n",
    "                            cond = image_snips[i-1, j, -1, :] * filt\n",
    "                            pos = (i-1) * image_snips.shape[0] + j\n",
    "                            locs_co = np.zeros((image_snips.shape[2], 2))\n",
    "                            locs_co[:,0] = i * image_snips.shape[2]\n",
    "                            locs_co[:,1] = j * image_snips.shape[2] + np.arange(image_snips.shape[2])\n",
    "                            \n",
    "                            for c in np.unique(cond).astype(np.int32):\n",
    "                                if c > 0:\n",
    "                                    loc_data[un_cluster].append((c, pos))\n",
    "                                    if not (c in interface[un_cluster]):\n",
    "                                        interface[un_cluster][c] = []\n",
    "                                    interface[un_cluster][c].append(locs_co[cond==c, :])\n",
    "                        if j > 0:\n",
    "                            filt = image_snips[i,j, :, 0] == un_cluster\n",
    "                            cond = image_snips[i, j-1, :, -1] * filt\n",
    "                            pos = (i) * image_snips.shape[0] + j-1\n",
    "                            locs_co = np.zeros((image_snips.shape[2], 2))\n",
    "                            locs_co[:,0] = i * image_snips.shape[2] + np.arange(image_snips.shape[2])\n",
    "                            locs_co[:,1] = j * image_snips.shape[2] \n",
    "                            for c in np.unique(cond).astype(np.int32):\n",
    "                                if c > 0:\n",
    "                                    loc_data[un_cluster].append((c, pos))\n",
    "                                    if not (c in interface[un_cluster]):\n",
    "                                        interface[un_cluster][c] = []\n",
    "                                    interface[un_cluster][c].append(locs_co[cond==c, :])\n",
    "                                    \n",
    "                        if i < (image_snips.shape[0] - 1):\n",
    "                            filt = image_snips[i,j, -1, :] == un_cluster\n",
    "                            cond = image_snips[i+1, j, 0, :] * filt\n",
    "                            pos = (i+1) * image_snips.shape[0] + j\n",
    "                            locs_co = np.zeros((image_snips.shape[2], 2))\n",
    "                            locs_co[:,0] = (i+1) * image_snips.shape[2] - 1\n",
    "                            locs_co[:,1] = j * image_snips.shape[2] + np.arange(image_snips.shape[2])\n",
    "                            for c in np.unique(cond).astype(np.int32):\n",
    "                                if c > 0:\n",
    "                                    loc_data[un_cluster].append((c, pos))\n",
    "                                    if not (c in interface[un_cluster]):\n",
    "                                        interface[un_cluster][c] = []\n",
    "                                    interface[un_cluster][c].append(locs_co[cond==c, :])\n",
    "                        if j < (image_snips.shape[0] - 1):\n",
    "                            filt = image_snips[i,j, :, -1] == un_cluster\n",
    "                            cond = image_snips[i, j+1, :, 0] * filt\n",
    "                            pos = (i) * image_snips.shape[0] + j + 1\n",
    "                            locs_co = np.zeros((image_snips.shape[2], 2))\n",
    "                            locs_co[:,0] = i * image_snips.shape[2] + np.arange(image_snips.shape[2])\n",
    "                            locs_co[:,1] = (j+1) * image_snips.shape[2] - 1 \n",
    "                            for c in np.unique(cond).astype(np.int32):\n",
    "                                if c > 0:\n",
    "                                    loc_data[un_cluster].append((c, pos))\n",
    "                                    if not (c in interface[un_cluster]):\n",
    "                                        interface[un_cluster][c] = []\n",
    "                                    interface[un_cluster][c].append(locs_co[cond==c, :])\n",
    "                    image_edges.append(loc_data)\n",
    "            interfaces.append(interface)\n",
    "            new_ie = []\n",
    "            smd = []\n",
    "            pos = []\n",
    "            nc = 0\n",
    "\n",
    "\n",
    "            for i in range(len(image_edges)):\n",
    "                for j in image_edges[i]:\n",
    "                    cont = image_edges[i][j]\n",
    "                    new_ie.append([j, j])\n",
    "                    pos_i = i % image_snips.shape[0]\n",
    "                    pos_j = i // image_snips.shape[0]\n",
    "                    pos.append([pos_i, pos_j])\n",
    "                    for k, item in enumerate(cont):\n",
    "                        new_ie.append([j, item[0]])\n",
    "                        for l, it2 in enumerate(cont):\n",
    "                            if k == l:\n",
    "                                continue\n",
    "                            smd.append([item[0], j, it2[0]])\n",
    "                        #xpos_i = item[1] % image_snips.shape[0]\n",
    "                        #xpos_j = item[1] // image_snips.shape[0]\n",
    "                        #pos.append([pos_i - xpos_i, pos_j - xpos_j])\n",
    "            assigners.append(image_edges)\n",
    "            new_ies.append(new_ie)\n",
    "            new_pos.append(np.asarray(pos))\n",
    "            smds.append(np.asarray(smd))\n",
    "\n",
    "        img = img.reshape(-1, 1, graph_size, graph_size)\n",
    "        #new_pos = np.asarray(new_pos)\n",
    "        #start = torch.cat([(data.start//graph_size).unsqueeze(1),\n",
    "        #                   (data.start%graph_size).unsqueeze(1)], axis=1)\n",
    "\n",
    "        #goal = torch.cat([(data.end//graph_size).unsqueeze(1),\n",
    "        #                  (data.end%graph_size).unsqueeze(1)], axis=1)\n",
    "        \n",
    "        #keeps = start.cpu()\n",
    "        #keepe = end.cpu()\n",
    "        #print(\"START TIME: \", time.time()-t0)\n",
    "        enc = encoders[0](img)\n",
    "        #print(\"ENCODE TIME: \", time.time()-t0)\n",
    "        enc = enc.permute(0, 2, 3, 1)\n",
    "        #enc = enc.reshape(enc.shape[0], -1, enc.shape[-1])\n",
    "        #enc1 = mappers[1](img)\n",
    "        #scores = encoder(img)\n",
    "        startrel = (start%reduction_rate[0])/reduction_rate[0]\n",
    "        endrel = (end%reduction_rate[0])/reduction_rate[0]\n",
    "        startr = start // reduction_rate[0]\n",
    "        endr = end // reduction_rate[0]\n",
    "        data = []\n",
    "        loc = []\n",
    "        start_flat = []\n",
    "        end_flat = []\n",
    "        for b in range(enc.shape[0]):\n",
    "            bdata = []          \n",
    "            benc = enc[b]\n",
    "            label = torch.Tensor(labels[b]).to(device)[:,:,0].type(torch.int64)\n",
    "            #for i in range(1, label.max()+1):\n",
    "            #    cx = torch.sum(benc[(label == i)], dim=0, keepdim=True)\n",
    "            #    #print(cx.shape)\n",
    "            #    bdata.append(cx)\n",
    "            #cur_x = torch.cat(bdata, axis=0)#enc[b]\n",
    "            \n",
    "            index = label.reshape(-1,)#.repeat(1, 8)\n",
    "            bbenc = benc.reshape(-1, benc.shape[-1])\n",
    "            #cur_x = torch.zeros((index.max()+1, benc.shape[-1]), dtype=bbenc.dtype).to(device)\n",
    "            cur_x = scatter(bbenc, index, 0, reduce=\"mean\")\n",
    "            cur_x = cur_x[1:]\n",
    "            #raise Exception(\"calculated\")\n",
    "            \n",
    "            #print(b, label.max(), cur_x.shape, len(new_pos[b]))\n",
    "            \n",
    "            for p in range(NUM_PATHS):\n",
    "                sstartr = startr[b,p, 0] * image_snips.shape[0] + startr[b,p, 1]\n",
    "                sendr = endr[b,p, 0] * image_snips.shape[0] + endr[b,p, 1]\n",
    "                cl = labels[b][start[b,p,0], start[b,p,1]]\n",
    "                el = labels[b][end[b,p,0], end[b,p,1]]\n",
    "                goal_selector = torch.zeros((cur_x.shape[0], 2), dtype=cur_x.dtype)\n",
    "                #print(cl, b, p)\n",
    "                start_flat.append(cl-1)\n",
    "                end_flat.append(el-1)\n",
    "                goal_selector[cl-1, 0] = 1\n",
    "                goal_selector[el-1, 1] = 1\n",
    "                dat = Data(x=torch.cat([cur_x, goal_selector.to(device)], axis=1),\n",
    "                           edge_index=torch.LongTensor(new_ies[b]).to(device)-1,\n",
    "                           edge_data=torch.Tensor(new_pos[b]),\n",
    "                          smds = torch.LongTensor(smds[b]).to(device)-1)\n",
    "                data.append(dat)\n",
    "        datas = data\n",
    "        data = data_list_batch(data)\n",
    "            \n",
    "        with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "            a, edge_vals, path_dist = maskers[0](data.x, data.edge_index.T,\n",
    "                                      data.edge_data, batch=data.batch, smds=data.smds.T)\n",
    "        #print(edge_vals.shape)\n",
    "        a_per_batch = batch_list_data(a, data.batch)\n",
    "        start = start.reshape(-1, 2)\n",
    "        end = end.reshape(-1, 2)\n",
    "        flatstart = (start[:, 1] + start[:,0]*graph_size).to(device)\n",
    "        flatend = (end[:, 1] + end[:,0]*graph_size).to(device)\n",
    "        new_a = []\n",
    "        \n",
    "        small_paths = []\n",
    "        small_paths_m = []\n",
    "        pure_paths = []\n",
    "        costs = []\n",
    "        #print(\"time before traverse: \", time.time() - t0)\n",
    "        edge_cut = 0\n",
    "        edge_cuts = []\n",
    "        \n",
    "        lengths = torch.zeros((data.smds.shape[0])) - 1\n",
    "        \n",
    "        for b, ab in enumerate(a_per_batch):\n",
    "            #print(ab.min())\n",
    "            ab_n = ab#torch.sigmoid(ab)\n",
    "            new_edges = datas[b].edge_index.cpu().numpy().T\n",
    "            G = nx.from_edgelist([(new_edges[0, e], new_edges[1,e])\n",
    "                                  for e in range(new_edges.shape[1])])\n",
    "            src, dst = new_edges\n",
    "            end_cut = edge_cut + new_edges.shape[1]\n",
    "            edge_cuts.append(edge_vals[edge_cut:end_cut])\n",
    "            dir_weights = 1 - edge_vals[edge_cut:end_cut].detach().cpu().numpy()#1 - 0.99*((ab_n[dst] - ab_n[src])[:,0].detach().cpu().numpy())\n",
    "            #if end_cut == edge_vals.shape[0]:\n",
    "            #    print(\"done 1\")\n",
    "            \n",
    "            dir_weights = dir_weights# - dir_weights.min()\n",
    "            dir_weights = {(new_edges[0, i], new_edges[1,i]):dir_weights[i] for i in range(dir_weights.shape[0])}\n",
    "            nx.set_edge_attributes(G, dir_weights, \"direction\")\n",
    "            #print(G.nodes, int(start_flat[b]), int(end_flat[b]))\n",
    "            L = nx.shortest_path(G, int(start_flat[b]), int(end_flat[b]), weight=\"direction\")\n",
    "            zer = torch.zeros_like(ab)\n",
    "            zer[L] = 1\n",
    "            zer = zer.detach()\n",
    "            small_paths.append(zer)\n",
    "            new_a.append(ab_n * zer + 0.0 * ab_n * (1-zer))\n",
    "            #EI = new_edges.T\n",
    "            #pairs = np.asarray([[L[i], L[i+1]] for i in range(len(L)-1)])\n",
    "            #res_0 = torch.zeros((EI.shape[0],))\n",
    "            #for i, pair in enumerate(pairs):\n",
    "            #    loc = np.where((EI == pair).all(axis=-1))[0]\n",
    "                #print(pair, loc)\n",
    "            #    res_0[loc] = 1\n",
    "            #raise Exception(\"\")\n",
    "            #small_paths_m.append(res_0)\n",
    "            L = nx.shortest_path(G, int(start_flat[b]), int(end_flat[b]))\n",
    "            cost_goal = ((datas[b].edge_data - datas[b].edge_data[int(end_flat[b])])**2).sum(axis=-1)\n",
    "            cost_start = ((datas[b].edge_data - datas[b].edge_data[int(start_flat[b])])**2).sum(axis=-1)\n",
    "            cost = torch.minimum(cost_start, cost_goal)\n",
    "            costs.append(cost)\n",
    "            zer = torch.zeros_like(ab)\n",
    "            zer[L] = 1\n",
    "            zer = zer.detach()\n",
    "            pure_paths.append(zer)\n",
    "            #print(zer.shape)\n",
    "            #ab = torch.sigmoid(ab)\n",
    "            edge_cut = end_cut\n",
    "        #a_per_batch = new_a\n",
    "            \n",
    "        mask_up = torch.zeros((enc.shape[0] * NUM_PATHS, graph_size, graph_size)).to(device)\n",
    "        temp_map = torch.zeros((reduction_rate[0], reduction_rate[0])).to(device)\n",
    "        for b in range(mask_up.shape[0]):\n",
    "            label = torch.Tensor(labels[b//NUM_PATHS]).to(device)\n",
    "            ab = new_a[b]\n",
    "            src = torch.cat([ab[:1]*0, ab], axis=0)\n",
    "            #raise Exception(\"\")\n",
    "            #for i in range(ab.shape[0]):\n",
    "            #    mask_temp = (label==(i+1))[:,:,0]\n",
    "            index = label.type(torch.int64).reshape(-1, 1)\n",
    "            mask_up[b] = torch.gather(src, 0, index.to(device)).reshape(graph_size, graph_size)\n",
    "        #mask_up = VF.gaussian_blur(mask_up, 15, 3)\n",
    "        mask_up = mask_up.reshape(img.shape[0] * NUM_PATHS, graph_sqr)\n",
    "        \n",
    "        \n",
    "        mask_small = torch.zeros((enc.shape[0] * NUM_PATHS, graph_size, graph_size)).to(device)\n",
    "        temp_map = torch.zeros((reduction_rate[0], reduction_rate[0])).to(device)\n",
    "        for b in range(mask_up.shape[0]):\n",
    "            label = torch.Tensor(labels[b//NUM_PATHS]).to(device)\n",
    "            ab = small_paths[b]\n",
    "            src = torch.cat([ab[:1]*0, ab], axis=0)\n",
    "            index = label.type(torch.int64).reshape(-1, 1)\n",
    "            mask_small[b] = torch.gather(src, 0, index).reshape(graph_size, graph_size)\n",
    "            #for i in range(ab.shape[0]):\n",
    "            #    mask_temp = (label==(i+1))[:,:,0]\n",
    "            #    mask_small[b,mask_temp] = ab[i]\n",
    "        \n",
    "        mask_small = mask_small.reshape(img.shape[0] * NUM_PATHS, graph_sqr).cpu()\n",
    "        \n",
    "        mask_pure = torch.zeros((enc.shape[0] * NUM_PATHS, graph_size, graph_size)).to(\"cpu\")\n",
    "        temp_map = torch.zeros((reduction_rate[0], reduction_rate[0])).to(\"cpu\")\n",
    "        for b in range(mask_up.shape[0]):\n",
    "            label = torch.Tensor(labels[b//NUM_PATHS]).to(\"cpu\")\n",
    "            ab = pure_paths[b].to(\"cpu\")\n",
    "            src = torch.cat([ab[:1]*0, ab], axis=0)\n",
    "            index = label.type(torch.int64).reshape(-1, 1)\n",
    "            mask_pure[b] = torch.gather(src, 0, index).reshape(graph_size, graph_size)\n",
    "            #for i in range(ab.shape[0]):\n",
    "            #    mask_temp = (label==(i+1))[:,:,0]\n",
    "            #    mask_pure[b,mask_temp] = (ab[i].to(\"cpu\"))\n",
    "        \n",
    "        mask_pure = mask_pure.reshape(img.shape[0] * NUM_PATHS, graph_sqr).cpu()\n",
    "        #mask_up1 = mask_up1.reshape(img.shape[0] * NUM_PATHS, graph_sqr)\n",
    "        \n",
    "        img = img.reshape(BATCH_SIZE, 1, graph_sqr).repeat([1, NUM_PATHS, 1])\n",
    "        \n",
    "        #print(\"BEFORE PATH: \", time.time()- t0)\n",
    "        \n",
    "        pmask_up = torch.zeros((mask_up.shape[0], graph_sqr))\n",
    "        pfollowed = torch.zeros((mask_up.shape[0], graph_sqr))\n",
    "        edge_res = []\n",
    "        path_best = []\n",
    "        path_algo = []\n",
    "        path_weights = []\n",
    "        bp = time.time()\n",
    "        smd_res = []\n",
    "        smd_masks = []\n",
    "        for p in range(mask_up.shape[0]):\n",
    "            label = torch.Tensor(labels[p//img.shape[1]])#.reshape(-1,)#.to(device)\n",
    "            edge_values = edge_cuts[p]\n",
    "            new_edges = datas[p].edge_index.cpu().numpy().T\n",
    "            #raise Exception()\n",
    "            cl = labels2[p//img.shape[1]][start[p,0], start[p,1]]\n",
    "            el = labels2[p//img.shape[1]][end[p,0], end[p,1]]\n",
    "            #print(start[p], end[p], cl, el)\n",
    "            #grid = labels2[p//img.shape[1],:,:,0] == cl\n",
    "            #inf_mask = grid == False\n",
    "            #grid = (grid*1.0).astype(np.float32)\n",
    "            #grid[inf_mask] = np.inf\n",
    "            #ab_ = (mask_up[p]).unsqueeze(-1)\n",
    "            #dist_vals = ab_#[dst] * ( 1 - 1*(ab_[dst] == ab_[src]))\n",
    "            #dir_weights = ((1 - (dist_vals)[:,0].detach().cpu().numpy())*100) ** 2\n",
    "            #dir_weights = dir_weights.reshape(grid.shape[0], grid.shape[1])\n",
    "            #locs = np.where((labels2[p//img.shape[1],:,:,0] == cl).reshape(-1,))[0]\n",
    "            #mask = np.isin(edge_maps, locs).all(axis=0)\n",
    "            #new_edges = edge_maps[:,mask]\n",
    "            #src, dst = new_edges\n",
    "            \n",
    "            #dir_weights = {(new_edges[0, i], new_edges[1,i]):dir_weights[i] for i in range(dir_weights.shape[0])}\n",
    "            #G = nx.from_edgelist([(new_edges[0, e], new_edges[1,e]) for e in range(new_edges.shape[1])])\n",
    "            #nx.set_edge_attributes(G, dir_weights, \"direction\")\n",
    "            #PL = astar_path(grid, np.asarray(start[p]), np.asarray(end[p]), allow_diagonal=False)\n",
    "            PL = astar_path((label.reshape(graph_size, graph_size).numpy()>0).astype(np.int32),\n",
    "                       new_edges.T.astype(np.int32),\n",
    "                       1-0*edge_values[:,0].detach().cpu().numpy(),\n",
    "                       np.asarray(start[p]), np.asarray(end[p]), allow_diagonal=False)\n",
    "            PL = PL[np.where((PL == np.asarray(start[p])).all(axis=-1))[0][0]:]\n",
    "            L = PL[:,0] * graph_size + PL[:,1]\n",
    "            path_nosc.append(len(L))\n",
    "            path_best.append(len(L))\n",
    "            #raise Exception(\"\")\n",
    "            \n",
    "            #grid = grid + dir_weights\n",
    "            \n",
    "            PL = astar_path(label[:,:,0].numpy().astype(np.int32),\n",
    "                       new_edges.T.astype(np.int32),\n",
    "                       (1*(1-edge_values[:,0].detach().cpu().numpy()))**2,\n",
    "                       np.asarray(start[p]), np.asarray(end[p]), allow_diagonal=False)\n",
    "            PL = PL[np.where((PL == np.asarray(start[p])).all(axis=-1))[0][0]:]\n",
    "            #PL = astar_path(grid, np.asarray(start[p]), np.asarray(end[p]), allow_diagonal=False)\n",
    "            L = PL[:,0] * graph_size + PL[:,1]\n",
    "            \n",
    "            #L = nx.astar_path(G, int(flatstart[p].cpu()), int(flatend[p].cpu()), nodedist, weight=\"direction\")\n",
    "            pairs = np.asarray([[L[i], L[i+1]] for i in range(len(L)-1)])\n",
    "            EI = datas[p].edge_index\n",
    "            res_0 = torch.zeros((EI.shape[0],))\n",
    "            #if len(pairs) < 2:\n",
    "            #    print(pairs)\n",
    "            #datas[p].smds\n",
    "            label = label.reshape(-1)\n",
    "            for i, pair in enumerate(pairs):\n",
    "                c_0 = label[pair[0]]\n",
    "                c_1 = label[pair[1]]\n",
    "                loc = torch.where((EI.cpu() == torch.Tensor([c_0, c_1])).all(axis=-1))[0]\n",
    "                \n",
    "                res_0[loc] = 1\n",
    "                #raise Exception(\"\")\n",
    "                #EI[:,0] == c_0) &\n",
    "            path_lens.append(len(L))\n",
    "            pmask_up[p, L] = 1\n",
    "            #path_nosc.append(len(L))\n",
    "            #path_olen.append(len(L))\n",
    "            #path_pure.append(len(L))\n",
    "            edge_res.append(res_0)\n",
    "            #\"\"\"\n",
    "            \n",
    "            grid = (labels2[p//img.shape[1],:,:,0] == cl)\n",
    "            grid = mask_small[p].reshape(graph_size, graph_size).cpu().numpy() * grid\n",
    "            #inf_mask = grid == False\n",
    "            grid = (grid*1).astype(np.int32)\n",
    "            #grid[inf_mask] = np.inf\n",
    "            #locs = np.where( * ((labels2[p//img.shape[1],:,:,0]) == cl).reshape(-1,))[0]\n",
    "            #mask = np.isin(edge_maps, locs).all(axis=0)\n",
    "            #new_edges = edge_maps[:,mask]\n",
    "            \n",
    "            #G = nx.from_edgelist([(new_edges[0, e], new_edges[1,e]) for e in range(new_edges.shape[1])])\n",
    "            \n",
    "            #L = nx.astar_path(G, int(flatstart[p].cpu()), int(flatend[p].cpu()), nodedist)\n",
    "            PL = astar_path(grid,\n",
    "                       new_edges.T.astype(np.int32),\n",
    "                       1-0*edge_values[:,0].detach().cpu().numpy(),\n",
    "                       np.asarray(start[p]), np.asarray(end[p]), allow_diagonal=False)\n",
    "            PL = PL[np.where((PL == np.asarray(start[p])).all(axis=-1))[0][0]:]\n",
    "            #PL = astar_path(grid, np.asarray(start[p]), np.asarray(end[p]), allow_diagonal=False)\n",
    "            L = PL[:,0] * graph_size + PL[:,1]\n",
    "            path_olen.append(len(L))\n",
    "            path_algo.append(len(L))\n",
    "            pfollowed[p, L] = 1\n",
    "            \n",
    "            grid = (labels2[p//img.shape[1],:,:,0] == cl)\n",
    "            grid = mask_pure[p].reshape(graph_size, graph_size).cpu().numpy() * grid\n",
    "            #inf_mask = grid == False\n",
    "            grid = (grid*1).astype(np.int32)\n",
    "            #grid[inf_mask] = np.inf\n",
    "            \n",
    "            PL = astar_path(grid,\n",
    "                       new_edges.T.astype(np.int32),\n",
    "                       1-0*edge_values[:,0].detach().cpu().numpy(),\n",
    "                       np.asarray(start[p]), np.asarray(end[p]), allow_diagonal=False)\n",
    "            PL = PL[np.where((PL == np.asarray(start[p])).all(axis=-1))[0][0]:]\n",
    "            #PL = astar_path(grid, np.asarray(start[p]), np.asarray(end[p]), allow_diagonal=False)\n",
    "            L = PL[:,0] * graph_size + PL[:,1]\n",
    "            #locs = np.where(mask_pure[p] * ((labels2[p//img.shape[1],:,:,0]) == cl).reshape(-1,))[0]\n",
    "            #mask = np.isin(edge_maps, locs).all(axis=0)\n",
    "            #new_edges = edge_maps[:,mask]\n",
    "            \n",
    "            #G = nx.from_edgelist([(new_edges[0, e], new_edges[1,e]) for e in range(new_edges.shape[1])])\n",
    "            \n",
    "            #L = nx.astar_path(G, int(flatstart[p].cpu()), int(flatend[p].cpu()), nodedist)\n",
    "            path_pure.append(len(L))\n",
    "            path_weights.append(np.abs(path_best[p] - path_algo[p]) * ((res_0*0 + 1)))\n",
    "            #\"\"\"\n",
    "            iface = interfaces[p//img.shape[1]]\n",
    "            cur_smd = datas[p].smds\n",
    "            label = torch.Tensor(labels[p//img.shape[1]])\n",
    "            smd_length = torch.zeros((cur_smd.shape[0]))\n",
    "            smd_mask = torch.zeros((cur_smd.shape[0]))\n",
    "            for s, smd in enumerate(cur_smd):\n",
    "                if np.random.uniform() < 0.1:\n",
    "                    cif = iface[int(smd[1])+1]\n",
    "                    ix, iy = cif[\"info\"]\n",
    "                    starts = np.concatenate(cif[int(smd[0])+1], axis=0).astype(np.int32)\n",
    "                    ends = np.concatenate(cif[int(smd[2])+1], axis=0).astype(np.int32)\n",
    "                    starts[:,0] = starts[:,0] - ix * image_snips.shape[2]\n",
    "                    starts[:,1] = starts[:,1] - iy * image_snips.shape[2]\n",
    "                    \n",
    "                    ends[:,0] = ends[:,0] - ix * image_snips.shape[2]\n",
    "                    ends[:,1] = ends[:,1] - iy * image_snips.shape[2]\n",
    "                    \n",
    "                    snip = label[ix*image_snips.shape[2]:(ix+1)*image_snips.shape[2],\n",
    "                                 iy*image_snips.shape[2]:(iy+1)*image_snips.shape[2]].numpy()\n",
    "                    snip_edges = np.ones((1, 2))\n",
    "                    snip_values = 0*np.random.random(size=1).astype(np.float32)#(np.arange(1,3) / 2).astype(np.float32)#np.zeros((1,))\n",
    "                    input_map = (snip.reshape(image_snips.shape[2],\n",
    "                                                   image_snips.shape[2])==(int(smd[1])+1)).astype(np.int32)\n",
    "                    PL = mastar_path(input_map,\n",
    "                                      snip_edges.T.astype(np.int32),\n",
    "                                      1-snip_values,\n",
    "                                      np.asarray(starts).reshape(-1,2),\n",
    "                                      np.asarray(ends).reshape(-1,2),\n",
    "                                      allow_diagonal=False)\n",
    "                    smd_length[s] = float(len(PL)) / 10\n",
    "                    smd_mask[s] = 1\n",
    "                    #raise Exception(\"\")\n",
    "            smd_res.append(smd_length)\n",
    "            smd_masks.append(smd_mask)\n",
    "        #print(\"AFTER PATH: \", time.time()- bp)\n",
    "        pmask_up = pmask_up.reshape(-1, 1, graph_size, graph_size)\n",
    "        \n",
    "        path_ups = []\n",
    "        temp_map = torch.zeros((reduction_rate[0], reduction_rate[0])).to(device)\n",
    "        for b in range(mask_up.shape[0]):\n",
    "            #path_up = torch.zeros_like(a_per_batch[b])\n",
    "            label = torch.Tensor(labels[b//NUM_PATHS]).to(\"cpu\").type(torch.int64)\n",
    "            pb = pmask_up[b].to(\"cpu\")\n",
    "            \n",
    "            index = label.reshape(-1,)#.repeat(1, 8)\n",
    "            bbenc = pb.reshape(-1, 1)#benc.reshape(-1, benc.shape[-1])\n",
    "            #cur_x = torch.zeros((index.max()+1, benc.shape[-1]), dtype=bbenc.dtype).to(device)\n",
    "            cur_x = scatter(bbenc, index, 0, reduce=\"max\")\n",
    "            cur_x = cur_x[1:]\n",
    "            #for i in range(path_up.shape[0]):\n",
    "            #    mask_temp = (label == i+1)[:,:,0]\n",
    "            #    path_up[i] = 1*((mask_temp * pb).any())\n",
    "            path_ups.append(cur_x > 0)\n",
    "            \n",
    "        if True:\n",
    "            pmask_up1 = torch.zeros((enc.shape[0] * NUM_PATHS, graph_size, graph_size)).to(\"cpu\")\n",
    "            temp_map = torch.zeros((reduction_rate[0], reduction_rate[0])).to(\"cpu\")\n",
    "            for b in range(pmask_up.shape[0]):\n",
    "                label = torch.Tensor(labels[b//NUM_PATHS]).to(\"cpu\")\n",
    "                ab = path_ups[b].to(\"cpu\")\n",
    "                src = torch.cat([ab[:1]*0, ab], axis=0)\n",
    "                index = label.type(torch.int64).reshape(-1, 1)\n",
    "                pmask_up1[b] = torch.gather(src, 0, index).reshape(graph_size, graph_size)\n",
    "                \n",
    "                #for i in range(ab.shape[0]):\n",
    "                #    mask_temp = (label==(i+1))[:,:,0]\n",
    "                #    pmask_up1[b,mask_temp] = (ab[i]*1.0).to(\"cpu\")\n",
    "                    \n",
    "        #raise Exception(\"\")\n",
    "        diff = edge_res#path_img.reshape(-1, graph_sqr).type(torch.float32)# * (goal_map[:,2:].sum(axis=1, keepdim=True) < 0.5)\n",
    "        diffx = torch.cat(diff, axis=0).type(torch.float32).to(device).unsqueeze(-1)\n",
    "        pw = torch.cat(path_weights, axis=0).type(torch.float32).to(device).unsqueeze(-1)\n",
    "        #chunk_probs = torch.cat(small_paths_m, axis=0).to(device)#torch.sigmoid(a)\n",
    "        #goal_mask = ((data.x[:,-2:] > 0)*1.0).max(axis=-1, keepdim=True).values\n",
    "        #diff_ng = (diff - goal_mask)\n",
    "        a_n = edge_vals# *  (1 - 0.75*(1 - chunk_probs))#torch.cat(new_a, axis=0)\n",
    "        #costs = torch.sqrt(torch.cat(costs, axis=0)/16).to(device)\n",
    "        loss1_ = (diffx * torch.log(torch.clip(a_n, 1e-6, 1 - 1e-6)))#loss_chunk(a_n, diff)# * costs\n",
    "        loss1 = -1*(loss1_ * (0+(pw))).sum() / data.x.shape[0]# + loss_chunk(a1, path_chunk1)\n",
    "        \n",
    "        # reg loss\n",
    "        smd_distances = torch.cat(smd_res, axis=0).type(torch.float32).unsqueeze(-1).to(device)\n",
    "        smd_mask = torch.cat(smd_masks, axis=0).type(torch.float32).unsqueeze(-1).to(device)\n",
    "        loss2 = torch.mean(torch.square(path_dist[smd_mask==1] - smd_distances[smd_mask==1]))\n",
    "        \n",
    "        loss = 0*loss1 + loss2\n",
    "        #loss2 = \n",
    "        #print(\"reached loss\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        diff = path_ups# * (goal_map[:,2:].sum(axis=1, keepdim=True) < 0.5)\n",
    "        diff = torch.cat(diff, axis=0).type(torch.float32).to(device)\n",
    "        chunk_probs = torch.cat(small_paths, axis=0)#torch.sigmoid(a)\n",
    "        #chunk_probs1 = torch.sigmoid(a1)\n",
    "        lssc_accum += loss1\n",
    "        path_lss += loss2\n",
    "        acc_curr = acc(a_n[diffx==1], diffx[diffx==1])\n",
    "        #print(acc_curr)\n",
    "        acc_accum1 += acc_curr# + acc(chunk_probs1, path_chunk1) \n",
    "        pres_accum1 += pres(a_n[diffx==1], diffx[diffx==1])# + pres(chunk_probs1, path_chunk1)\n",
    "        rec_accum1 += rec(a_n[diffx==1], diffx[diffx==1])# + rec(chunk_probs1, path_chunk1)\n",
    "        #print(\"AFTER OPTIM: \", time.time() - t0)\n",
    "        #raise Exception(\"\")\n",
    "    path_lens = np.asarray(path_lens)\n",
    "    path_olen = np.asarray(path_olen)\n",
    "    path_nosc = np.asarray(path_nosc)\n",
    "    path_pure = np.asarray(path_pure)\n",
    "    print(f\"Epoch Chunk: {epoch} Time: {time.time() - tepoch:.2f} \\\n",
    "    Loss: {lssc_accum/(idx+1):.4f} \\\n",
    "    MPL: {path_lss/(idx+1):.4f} \\\n",
    "    Precision: {pres_accum1/(idx+1):.2f} Recall: {rec_accum1/(idx+1):.2f} \\\n",
    "    Scored Path: {np.mean(path_nosc/path_lens):.3f} \\\n",
    "    Masked Path: {np.mean(path_nosc/path_olen):.3f} \\\n",
    "    A* Masked Path: {np.mean(path_nosc/path_pure):.3f}\" )\n",
    "    #print(f\"Epoch: {epoch} Loss: {lss_accum/(l+1)} Accuracy: {acc_accum/(l+1)} Precision: {pres_accum/(l+1)} Recall: {rec_accum/(l+1)}\")\n",
    "    #if True:\n",
    "    #    vismap = visualize(img[-1,0].cpu(), start[-1].cpu(), end[-1].cpu(), path_sec.cpu()[-1], probs.cpu()[-1])\n",
    "    #    plt.imshow(vismap)\n",
    "    #    plt.show()\n",
    "    #    print(\"updated\")\n",
    "        #raise Exception(\"\")\n",
    "    noise_effect *= 0.97\n",
    "    #raise Exception(\"\")\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8485dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.square(path_dist[smd_mask==1] - smd_distances[smd_mask==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b0f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "smd_distances[smd_mask==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88001ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dist[smd_mask==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c2d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(input_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe36aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b460e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid,\n",
    "                       new_edges.T.astype(np.int32),\n",
    "                       1-0*edge_values[:,0].detach().cpu().numpy(),\n",
    "                       np.asarray(start[p]), np.asarray(end[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f3cdc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pymastar2d import mastar_path\n",
    "PL = mastar_path(grid,\n",
    "                new_edges.T.astype(np.int32),\n",
    "                1-0*edge_values[:,0].detach().cpu().numpy(),\n",
    "                np.asarray(start[p]).reshape(1,2), np.asarray(end[p]).reshape(1,2), allow_diagonal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17246b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PL = mastar_path(input_map,\n",
    "                                      snip_edges.T.astype(np.int32),\n",
    "                                      1-(snip_values/2).astype(np.float32),\n",
    "                                      np.asarray(starts).reshape(-1,2),\n",
    "                                      np.asarray(ends).reshape(-1,2),\n",
    "                                      allow_diagonal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bba92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - snip_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "end[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = grid\n",
    "edges = new_edges.T.astype(np.int32)\n",
    "trans = 1-0*edge_values[:,0].detach().cpu().numpy()\n",
    "st = np.asarray(start[p:p+1])\n",
    "goal = np.asarray(end[p:p+1])\n",
    "height, width = weights.shape\n",
    "start_idx = np.ravel_multi_index(st.T, (height, width))\n",
    "goal_idx = np.ravel_multi_index(goal.T, (height, width))\n",
    "m = edges.shape[0]\n",
    "#res = pyastar2d.astar.multi_point_astar(weights.flatten(), edges.flatten(), trans.flatten(),\n",
    "#                                  height, width, m, start_idx, goal_idx, 1, 1, False, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b246b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eef2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b43542",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = [path_nosc, path_lens, path_olen, path_pure]\n",
    "exp = [np.expand_dims(e, axis=-1) for e in exp]\n",
    "con_path = np.concatenate(exp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c67230",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 128))\n",
    "gs = fig.add_gridspec(mask_up.shape[0], 4, hspace=0, wspace=0)\n",
    "axs = gs.subplots(sharex=True, sharey=True)\n",
    "for b in range(mask_up.shape[0]):\n",
    "    axs[b,0].imshow(mask_up[b].reshape(graph_size, graph_size).detach().cpu())\n",
    "    axs[b,1].imshow(pfollowed[b].reshape(graph_size, graph_size).detach().cpu())\n",
    "    axs[b,2].imshow(pmask_up[b].reshape(graph_size, graph_size).detach().cpu())\n",
    "    axs[b,3].imshow(pmask_up1[b].reshape(graph_size, graph_size).detach().cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e3103d",
   "metadata": {
    "id": "03e3103d"
   },
   "outputs": [],
   "source": [
    "edge_res[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5316d027",
   "metadata": {
    "id": "5316d027"
   },
   "outputs": [],
   "source": [
    "(labels[0] == labels[3]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3bf89c",
   "metadata": {
    "id": "7b3bf89c"
   },
   "outputs": [],
   "source": [
    "len(list(mappers[0].parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a70d9f",
   "metadata": {
    "id": "38a70d9f"
   },
   "outputs": [],
   "source": [
    "a = torch.arange(10)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f5d4f",
   "metadata": {
    "id": "335f5d4f"
   },
   "outputs": [],
   "source": [
    "torch.gather(a, 0, torch.LongTensor([0,0, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b47f5",
   "metadata": {
    "id": "183b47f5"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f9d11e",
   "metadata": {
    "id": "39f9d11e"
   },
   "outputs": [],
   "source": [
    "plt.imshow(out.reshape(8, 64, 64).detach().cpu()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e96c5",
   "metadata": {
    "id": "630e96c5"
   },
   "outputs": [],
   "source": [
    "map = cv2.imread(\"bg512-png\\AR0011SR.png\",0)\n",
    "map = 1*(cv2.resize(map, (graph_size, graph_size)) > 127)\n",
    "#map = r.reshape(graph_size, graph_size, 1)\n",
    "#label, num = scipy.ndimage.label(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da94de6",
   "metadata": {
    "id": "1da94de6"
   },
   "outputs": [],
   "source": [
    "plt.imshow(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc32d3",
   "metadata": {
    "id": "86fc32d3"
   },
   "outputs": [],
   "source": [
    "d = batch_list_data(a, data.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f7f7f",
   "metadata": {
    "id": "c37f7f7f"
   },
   "outputs": [],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8835dbe8",
   "metadata": {
    "id": "8835dbe8"
   },
   "outputs": [],
   "source": [
    "plt.imshow(valid_mask.reshape(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb90447",
   "metadata": {
    "id": "4fb90447"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcce9628",
   "metadata": {
    "id": "bcce9628"
   },
   "outputs": [],
   "source": [
    "out[batch_dim == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61a67e3",
   "metadata": {
    "id": "b61a67e3"
   },
   "outputs": [],
   "source": [
    "edge_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f50ed",
   "metadata": {
    "id": "7a2f50ed"
   },
   "outputs": [],
   "source": [
    "torch.save(mapper.state_dict(), \"mapper.pt\")\n",
    "torch.save(decoder.state_dict(), \"decoder.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7yItP3_IzqBL",
   "metadata": {
    "id": "7yItP3_IzqBL"
   },
   "outputs": [],
   "source": [
    "img_graph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d58ae",
   "metadata": {
    "id": "691d58ae"
   },
   "outputs": [],
   "source": [
    "path_chunk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab54038",
   "metadata": {
    "id": "cab54038"
   },
   "outputs": [],
   "source": [
    "plt.imshow(detached[4].reshape(graph_size, graph_size).cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea94ea",
   "metadata": {
    "id": "8fea94ea"
   },
   "outputs": [],
   "source": [
    "plt.imshow(probs[4].reshape(graph_size, graph_size).cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db027ce4",
   "metadata": {
    "id": "db027ce4"
   },
   "outputs": [],
   "source": [
    "plt.imshow(chunk_probs[4, 0].cpu().detach() > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a770dc",
   "metadata": {
    "id": "42a770dc"
   },
   "outputs": [],
   "source": [
    "a_per_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4427ced",
   "metadata": {
    "id": "d4427ced"
   },
   "outputs": [],
   "source": [
    "torch.masked_select(out, out>-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1392c1a",
   "metadata": {
    "id": "e1392c1a"
   },
   "outputs": [],
   "source": [
    "\n",
    "ig = extract_image_patches(img, reduction_rate, stride=reduction_rate)\n",
    "ig = ig.reshape(img.shape[0], reduction_rate, reduction_rate, enc_size, enc_size)\n",
    "\n",
    "        \n",
    "class MaskSelect(torch.nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, img_patched, mask):\n",
    "        batch_size = img_patched.shape[0]\n",
    "        num_paths = mask.shape[0] // batch_size\n",
    "        \n",
    "        path_chunk = chunk_probs.unsqueeze(2).unsqueeze(2)\n",
    "        \n",
    "        out = torch.masked_select(ig, chunk_probs>0.5).reshape(path_chunk, path_chunk, -1).permute([2, 0, 1])\n",
    "        \n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6987f622",
   "metadata": {
    "id": "6987f622"
   },
   "outputs": [],
   "source": [
    "plt.imshow((path_chunk[0]>0.5).cpu().detach().reshape(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aff1d0",
   "metadata": {
    "id": "c6aff1d0"
   },
   "outputs": [],
   "source": [
    "goal_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f82ace5",
   "metadata": {
    "id": "4f82ace5"
   },
   "outputs": [],
   "source": [
    "enc_up.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394729a6",
   "metadata": {
    "id": "394729a6"
   },
   "outputs": [],
   "source": [
    "plt.imshow(path[0].cpu().detach().reshape(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46525e78",
   "metadata": {
    "id": "46525e78"
   },
   "outputs": [],
   "source": [
    "plt.imshow((probs[0]>0.5).cpu().detach().reshape(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2cd89a",
   "metadata": {
    "id": "fe2cd89a"
   },
   "outputs": [],
   "source": [
    "data=data.cpu()\n",
    "path=pure_hist[0].cpu()\n",
    "history = probs[0].cpu()\n",
    "map = np.zeros((graph_size*graph_size, 3))\n",
    "#edges = data.edge_index[0,:]\n",
    "#edges = edges[edges<(graph_size*graph_size)]\n",
    "#map[edges, :] = 1\n",
    "map[:,:] = data.x[:graph_size*graph_size]\n",
    "#print(path.shape, history.shape, data.x[:graph_size*graph_size].shape)\n",
    "path = path * data.x[:graph_size*graph_size,0]\n",
    "history = history * data.x[:graph_size*graph_size,0]\n",
    "empty_map = map[:,:1]\n",
    "map[path>0] = [0,0,0]\n",
    "\n",
    "history = history>0.5\n",
    "map[history] = [1,0.5,0]\n",
    "\n",
    "map[path>0] = map[path>0] + [0, 0.5, 0]\n",
    "\n",
    "#map = map * (empty_map)\n",
    "map[data.start[0], :] = [0, 0, 1]\n",
    "map[data.end[0], :] = [1, 0, 0]\n",
    "map = np.clip(map, 0, 1)\n",
    "\n",
    "map = map.reshape(graph_size, graph_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d25210",
   "metadata": {
    "id": "36d25210"
   },
   "outputs": [],
   "source": [
    "def dist(a, b):\n",
    "    (x1, y1) = a\n",
    "    (x2, y2) = b\n",
    "    return ((x1 - x2) ** 2 + (y1 - y2) ** 2) ** 0.5\n",
    "\n",
    "t0 =time.time()\n",
    "glob_grid = nx.grid_2d_graph(512, 512)\n",
    "glob_grid.remove_nodes_from(np.where(1-img[0,0].reshape(-1).cpu())[0])\n",
    "nx.astar_path(glob_grid, (427, 166), (105, 480), dist)\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec46175c",
   "metadata": {
    "id": "ec46175c"
   },
   "outputs": [],
   "source": [
    "filters = torch.randn(1, 1, 103)\n",
    "inputs = torch.randn(32, 1, 2500)\n",
    "\n",
    "filters = filters.to(device)\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "F.conv1d(inputs, filters, padding=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9520c121",
   "metadata": {
    "id": "9520c121"
   },
   "outputs": [],
   "source": [
    "torch.Tensor(filters).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77997193",
   "metadata": {
    "id": "77997193"
   },
   "outputs": [],
   "source": [
    "x = selected_node_maps.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b0290",
   "metadata": {
    "id": "9c7b0290"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6144d5",
   "metadata": {
    "id": "9d6144d5"
   },
   "outputs": [],
   "source": [
    "n, d= reduce_graph(edge_map.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478eb80d",
   "metadata": {
    "id": "478eb80d"
   },
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca3b0d",
   "metadata": {
    "id": "73ca3b0d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "%matplotlib inline  \n",
    "optimizer = torch.optim.RMSprop(list(mapper.parameters()) + list(decoder.parameters()), lr=1e-2)\n",
    "#find_path = ASTAR(8, graph_size)\n",
    "TRAIN_LIMIT = 10\n",
    "def visualize(data=None, start=None, end=None, path=None, history=None):\n",
    "\n",
    "    map = np.zeros((graph_size*graph_size, 3))\n",
    "    #edges = data.edge_index[0,:]\n",
    "    #edges = edges[edges<(graph_size*graph_size)]\n",
    "    #map[edges, :] = 1\n",
    "    data = data.reshape(-1, 1)\n",
    "    map[:,:] = data\n",
    "    #print(path.shape, history.shape, data.x[:graph_size*graph_size].shape)\n",
    "    path = path * data[:,0]\n",
    "    history = history * data[:,0]\n",
    "    empty_map = map[:,:1]\n",
    "    map[path>0] = [0,0,0]\n",
    "\n",
    "    history = history>0.5\n",
    "    map[history] = [1,0.5,0]\n",
    "\n",
    "    map[path>0] = map[path>0] + [0, 0.5, 0]\n",
    "\n",
    "    #map = map * (empty_map)\n",
    "    \n",
    "\n",
    "    map = map.reshape(graph_size, graph_size, 3)\n",
    "    \n",
    "    map[start[0], start[1], :] = [0, 0, 1]\n",
    "    map[end[0], end[1], :] = [1, 0, 0]\n",
    "    map = np.clip(map, 0, 1)\n",
    "    \n",
    "    return map\n",
    "\n",
    "#model.train()\n",
    "noise_effect = 1\n",
    "for epoch in range(20000):\n",
    "    lss_accum = 0\n",
    "    acc_accum = 0\n",
    "    pres_accum = 0\n",
    "    pres_base = 0\n",
    "    rec_accum = 0\n",
    "    for l, batch in enumerate(train_loader):\n",
    "        loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        img = batch[0].to(device)\n",
    "        start = batch[1].to(device)\n",
    "        end = batch[2].to(device)\n",
    "        em = batch[3].to(device)\n",
    "        t0 = time.time()\n",
    "        img = img.reshape(-1, 1, graph_size, graph_size)\n",
    "        goal_map = torch.zeros((img.shape[0], 2,\n",
    "                                img.shape[2]//(reduction_rate),\n",
    "                                img.shape[3]//(reduction_rate))).to(device)\n",
    "        \n",
    "        #start = torch.cat([(data.start//graph_size).unsqueeze(1),\n",
    "        #                   (data.start%graph_size).unsqueeze(1)], axis=1)\n",
    "        \n",
    "        #goal = torch.cat([(data.end//graph_size).unsqueeze(1),\n",
    "        #                  (data.end%graph_size).unsqueeze(1)], axis=1)\n",
    "        startrel = (start%reduction_rate)/reduction_rate\n",
    "        endrel = (end%reduction_rate)/reduction_rate\n",
    "        startr = start // reduction_rate\n",
    "        endr = end // reduction_rate\n",
    "        #keeps = start.cpu()\n",
    "        #keepe = end.cpu()\n",
    "        enc = mapper(img)\n",
    "        if epoch>TRAIN_LIMIT:\n",
    "            for p in range(NUM_PATHS):\n",
    "                goal_map = torch.zeros((img.shape[0], 2,\n",
    "                                    img.shape[2]//(reduction_rate),\n",
    "                                    img.shape[3]//(reduction_rate))).to(device)\n",
    "                goal_map[range(img.shape[0]), :, startr[:, p,0], startr[:,p,1]] += startrel[:,p,:] + 1\n",
    "                goal_map[range(img.shape[0]), :, endr[:,p,0], endr[:,p,1]] += endrel[:,p,:] + 1\n",
    "                out, chunk_preds = decoder(enc, goal_map, em.squeeze(0), False)\n",
    "                #out, chunk_preds = model(img, goal_map)\n",
    "                out = out.reshape(1, -1)\n",
    "                out = out# + noise_effect*torch.normal(mean=out*0, std=out*0+1).detach()\n",
    "                probs = torch.sigmoid(out)\n",
    "                t1 = time.time()\n",
    "                flatstart = start[:,p, 1] + start[:,p,0]*graph_size\n",
    "                flatend = end[:,p, 1] + end[:,p,0]*graph_size\n",
    "                #history, path_fin = find_path(probs, data, True)\n",
    "                pure_hist, path_sec = find_path(0.01*(1-probs).detach(),\n",
    "                                                flatstart.detach(),\n",
    "                                                flatend.detach(),\n",
    "                                                img.detach(), True)\n",
    "\n",
    "                path_img = path_sec.reshape(-1, 1, graph_size, graph_size)\n",
    "                path_chunk = F.conv2d(path_img.type(torch.float32), chunk_filter, padding=\"valid\",\n",
    "                                      stride = reduction_rate)\n",
    "                path_chunk = (path_chunk > 0.9).type(torch.float32).detach()\n",
    "                t2 = time.time()\n",
    "                #print(\"TIMES: \", t1-t0, t2-t1)\n",
    "                detached = path_sec.detach().type(torch.float32)\n",
    "                loss += 100*loss_func(out, detached) + 100*loss_func(chunk_preds, path_chunk)\n",
    "            #print(out.shape, data.y.shape)\n",
    "            acc_accum += acc(probs, detached)\n",
    "            pres_accum += pres(probs, detached)\n",
    "            rec_accum += rec(probs, detached)\n",
    "            lss_accum += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            #zero_grid = torch.zeros((1, graph_size*graph_size)).to(device)\n",
    "            for p in range(NUM_PATHS):\n",
    "                goal_map = torch.zeros((img.shape[0], 2,\n",
    "                                    img.shape[2]//(reduction_rate),\n",
    "                                    img.shape[3]//(reduction_rate))).to(device)\n",
    "                goal_map[range(img.shape[0]), :, startr[:, p,0], startr[:,p,1]] += startrel[:,p,:] + 1\n",
    "                goal_map[range(img.shape[0]), :, endr[:,p,0], endr[:,p,1]] += endrel[:,p,:] + 1\n",
    "                chunk_preds = decoder(enc, goal_map, em.squeeze(0), True)\n",
    "                out = torch.sigmoid(chunk_preds)\n",
    "                for d in range(depth):\n",
    "                    out = torch.repeat_interleave(torch.repeat_interleave(out, 2, dim=2), 2, dim=3)\n",
    "                #out, chunk_preds = model(img, goal_map)\n",
    "                out = out.reshape(1, -1)\n",
    "                #out = out# + noise_effect*torch.normal(mean=out*0, std=out*0+1).detach()\n",
    "                probs = torch.sigmoid(chunk_preds)\n",
    "                t1 = time.time()\n",
    "                flatstart = start[:,p, 1] + start[:,p,0]*graph_size\n",
    "                flatend = end[:,p, 1] + end[:,p,0]*graph_size\n",
    "                #history, path_fin = find_path(probs, data, True)\n",
    "                \n",
    "                pure_hist, path_sec = find_path(0.1*(1-out).detach(),\n",
    "                                                flatstart.detach(),\n",
    "                                                flatend.detach(),\n",
    "                                                img.detach(), True)\n",
    "\n",
    "                path_img = path_sec.reshape(-1, 1, graph_size, graph_size)\n",
    "                path_chunk = F.conv2d(path_img.type(torch.float32), chunk_filter, padding=\"valid\",\n",
    "                                      stride = reduction_rate)\n",
    "                path_chunk = (path_chunk > 0.9).type(torch.float32).detach()\n",
    "                t2 = time.time()\n",
    "                #print(\"TIMES: \", t1-t0, t2-t1)\n",
    "                detached = path_sec.detach().type(torch.float32)\n",
    "                loss += 100*loss_func(chunk_preds, path_chunk)\n",
    "            #print(out.shape, data.y.shape)\n",
    "            acc_accum += acc(probs, path_chunk)\n",
    "            pres_accum += pres(probs, path_chunk)\n",
    "            rec_accum += rec(probs, path_chunk)\n",
    "            lss_accum += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        #raise Exception(\"\")\n",
    "    print(f\"Epoch: {epoch} Loss: {lss_accum/(l+1)} Accuracy: {acc_accum/(l+1)} Precision: {pres_accum/(l+1)} Recall: {rec_accum/(l+1)}\")\n",
    "    if epoch>TRAIN_LIMIT:\n",
    "        vismap = visualize(img[0].cpu(), start[0,-1].cpu(), end[0,-1].cpu(), pure_hist.cpu()[0], probs.cpu()[0])\n",
    "        plt.imshow(vismap)\n",
    "        plt.show()\n",
    "        print(\"updated\")\n",
    "    noise_effect *= 0.97\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43145d1",
   "metadata": {
    "id": "b43145d1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe463c",
   "metadata": {
    "id": "d7fe463c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
